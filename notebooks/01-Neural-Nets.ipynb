{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd5ad85",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f004bbb-09cb-4537-a47b-64fd638c8a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Hides the GPU from TensorFlow\n",
    "tf.config.set_visible_devices([], 'GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19722b",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10c9f9ce-226c-456a-9aef-a11359189e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('~/Documents/My Docs/Advance Topics in PA/APA Project FIiles/proc_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b719939b-3937-4e57-9b94-3b76cd87b9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_time</th>\n",
       "      <th>final_time</th>\n",
       "      <th>section</th>\n",
       "      <th>cavity</th>\n",
       "      <th>gobdiameteraverage_avg</th>\n",
       "      <th>gobdiameteraverage_min</th>\n",
       "      <th>gobdiameteraverage_max</th>\n",
       "      <th>gobdiameteraverage_std</th>\n",
       "      <th>goblengthaverage_avg</th>\n",
       "      <th>goblengthaverage_min</th>\n",
       "      <th>...</th>\n",
       "      <th>center_top_tc_std</th>\n",
       "      <th>feeder_global_avg</th>\n",
       "      <th>feeder_global_min</th>\n",
       "      <th>feeder_global_max</th>\n",
       "      <th>feeder_global_diff_min_max</th>\n",
       "      <th>feeder_global_std</th>\n",
       "      <th>rejected_Sidewall</th>\n",
       "      <th>total_Sidewall</th>\n",
       "      <th>perc_defects_Sidewall</th>\n",
       "      <th>Defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-12 01:00:00</td>\n",
       "      <td>2023-03-12 02:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>216.973754</td>\n",
       "      <td>256.843423</td>\n",
       "      <td>74.786813</td>\n",
       "      <td>1.721593</td>\n",
       "      <td>999.922865</td>\n",
       "      <td>2899.599404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463084</td>\n",
       "      <td>3428.739146</td>\n",
       "      <td>9843.346673</td>\n",
       "      <td>6877.315512</td>\n",
       "      <td>145.198518</td>\n",
       "      <td>0.573705</td>\n",
       "      <td>4.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>0.008949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-12 01:20:00</td>\n",
       "      <td>2023-03-12 02:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>217.354264</td>\n",
       "      <td>256.843423</td>\n",
       "      <td>74.849225</td>\n",
       "      <td>1.933347</td>\n",
       "      <td>998.190252</td>\n",
       "      <td>2885.091023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501175</td>\n",
       "      <td>3428.837231</td>\n",
       "      <td>9843.686790</td>\n",
       "      <td>6877.315512</td>\n",
       "      <td>144.947527</td>\n",
       "      <td>0.597657</td>\n",
       "      <td>3.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-12 01:40:00</td>\n",
       "      <td>2023-03-12 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>217.518977</td>\n",
       "      <td>257.431206</td>\n",
       "      <td>74.849225</td>\n",
       "      <td>1.687425</td>\n",
       "      <td>1000.830804</td>\n",
       "      <td>2885.091023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477411</td>\n",
       "      <td>3428.863085</td>\n",
       "      <td>9844.792173</td>\n",
       "      <td>6876.733073</td>\n",
       "      <td>143.504326</td>\n",
       "      <td>0.581349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-12 02:00:00</td>\n",
       "      <td>2023-03-12 03:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>218.170264</td>\n",
       "      <td>257.431206</td>\n",
       "      <td>75.523022</td>\n",
       "      <td>2.111324</td>\n",
       "      <td>1004.892344</td>\n",
       "      <td>2885.091023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463842</td>\n",
       "      <td>3428.932190</td>\n",
       "      <td>9844.962232</td>\n",
       "      <td>6876.733073</td>\n",
       "      <td>143.378831</td>\n",
       "      <td>0.532321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-12 02:20:00</td>\n",
       "      <td>2023-03-12 03:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>218.828967</td>\n",
       "      <td>257.431206</td>\n",
       "      <td>75.690798</td>\n",
       "      <td>2.565130</td>\n",
       "      <td>1005.932142</td>\n",
       "      <td>2885.091023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428316</td>\n",
       "      <td>3428.971152</td>\n",
       "      <td>9846.322703</td>\n",
       "      <td>6876.733073</td>\n",
       "      <td>142.374865</td>\n",
       "      <td>0.462686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          initial_time           final_time  section  cavity  \\\n",
       "0  2023-03-12 01:00:00  2023-03-12 02:20:00        1       2   \n",
       "1  2023-03-12 01:20:00  2023-03-12 02:40:00        1       2   \n",
       "2  2023-03-12 01:40:00  2023-03-12 03:00:00        1       2   \n",
       "3  2023-03-12 02:00:00  2023-03-12 03:20:00        1       2   \n",
       "4  2023-03-12 02:20:00  2023-03-12 03:40:00        1       2   \n",
       "\n",
       "   gobdiameteraverage_avg  gobdiameteraverage_min  gobdiameteraverage_max  \\\n",
       "0              216.973754              256.843423               74.786813   \n",
       "1              217.354264              256.843423               74.849225   \n",
       "2              217.518977              257.431206               74.849225   \n",
       "3              218.170264              257.431206               75.523022   \n",
       "4              218.828967              257.431206               75.690798   \n",
       "\n",
       "   gobdiameteraverage_std  goblengthaverage_avg  goblengthaverage_min  ...  \\\n",
       "0                1.721593            999.922865           2899.599404  ...   \n",
       "1                1.933347            998.190252           2885.091023  ...   \n",
       "2                1.687425           1000.830804           2885.091023  ...   \n",
       "3                2.111324           1004.892344           2885.091023  ...   \n",
       "4                2.565130           1005.932142           2885.091023  ...   \n",
       "\n",
       "   center_top_tc_std  feeder_global_avg  feeder_global_min  feeder_global_max  \\\n",
       "0           0.463084        3428.739146        9843.346673        6877.315512   \n",
       "1           0.501175        3428.837231        9843.686790        6877.315512   \n",
       "2           0.477411        3428.863085        9844.792173        6876.733073   \n",
       "3           0.463842        3428.932190        9844.962232        6876.733073   \n",
       "4           0.428316        3428.971152        9846.322703        6876.733073   \n",
       "\n",
       "   feeder_global_diff_min_max  feeder_global_std  rejected_Sidewall  \\\n",
       "0                  145.198518           0.573705                4.0   \n",
       "1                  144.947527           0.597657                3.0   \n",
       "2                  143.504326           0.581349                2.0   \n",
       "3                  143.378831           0.532321                0.0   \n",
       "4                  142.374865           0.462686                0.0   \n",
       "\n",
       "   total_Sidewall  perc_defects_Sidewall  Defects  \n",
       "0           447.0               0.008949        0  \n",
       "1           464.0               0.006466        0  \n",
       "2           469.0               0.004264        0  \n",
       "3           460.0               0.000000        0  \n",
       "4           448.0               0.000000        0  \n",
       "\n",
       "[5 rows x 240 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a58890e-103c-46a1-8bc7-b51bdad14d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239320, 239)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c67fbd4d-89ce-4c15-8b13-519e6cff28ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>cavity</th>\n",
       "      <th>gobdiameteraverage_avg</th>\n",
       "      <th>gobdiameteraverage_min</th>\n",
       "      <th>gobdiameteraverage_max</th>\n",
       "      <th>gobdiameteraverage_std</th>\n",
       "      <th>goblengthaverage_avg</th>\n",
       "      <th>goblengthaverage_min</th>\n",
       "      <th>goblengthaverage_max</th>\n",
       "      <th>goblengthaverage_std</th>\n",
       "      <th>...</th>\n",
       "      <th>center_top_tc_max</th>\n",
       "      <th>center_top_tc_std</th>\n",
       "      <th>feeder_global_avg</th>\n",
       "      <th>feeder_global_min</th>\n",
       "      <th>feeder_global_max</th>\n",
       "      <th>feeder_global_diff_min_max</th>\n",
       "      <th>feeder_global_std</th>\n",
       "      <th>rejected_Sidewall</th>\n",
       "      <th>total_Sidewall</th>\n",
       "      <th>perc_defects_Sidewall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "      <td>239320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.237155</td>\n",
       "      <td>2.018586</td>\n",
       "      <td>241.217198</td>\n",
       "      <td>284.306529</td>\n",
       "      <td>83.505213</td>\n",
       "      <td>5.315899</td>\n",
       "      <td>937.774799</td>\n",
       "      <td>2707.030744</td>\n",
       "      <td>3165.014974</td>\n",
       "      <td>24.444875</td>\n",
       "      <td>...</td>\n",
       "      <td>3172.712382</td>\n",
       "      <td>1.075827</td>\n",
       "      <td>3426.013520</td>\n",
       "      <td>9853.180678</td>\n",
       "      <td>6887.666297</td>\n",
       "      <td>149.092685</td>\n",
       "      <td>1.389070</td>\n",
       "      <td>7.194911</td>\n",
       "      <td>465.633754</td>\n",
       "      <td>0.014636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.832643</td>\n",
       "      <td>0.815209</td>\n",
       "      <td>13.621712</td>\n",
       "      <td>16.689874</td>\n",
       "      <td>4.672913</td>\n",
       "      <td>5.210246</td>\n",
       "      <td>82.323839</td>\n",
       "      <td>238.759298</td>\n",
       "      <td>279.432126</td>\n",
       "      <td>38.442730</td>\n",
       "      <td>...</td>\n",
       "      <td>7.357667</td>\n",
       "      <td>17.973202</td>\n",
       "      <td>7.441552</td>\n",
       "      <td>116.776806</td>\n",
       "      <td>19.418643</td>\n",
       "      <td>88.065655</td>\n",
       "      <td>4.410788</td>\n",
       "      <td>35.552139</td>\n",
       "      <td>430.267551</td>\n",
       "      <td>0.018720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.900988</td>\n",
       "      <td>58.621037</td>\n",
       "      <td>17.333118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.396127</td>\n",
       "      <td>98.783256</td>\n",
       "      <td>478.742964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3152.492339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3406.899953</td>\n",
       "      <td>4769.130543</td>\n",
       "      <td>6840.563652</td>\n",
       "      <td>96.631685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>233.922123</td>\n",
       "      <td>275.288268</td>\n",
       "      <td>81.055125</td>\n",
       "      <td>2.340674</td>\n",
       "      <td>879.416214</td>\n",
       "      <td>2538.554936</td>\n",
       "      <td>2967.742463</td>\n",
       "      <td>9.670093</td>\n",
       "      <td>...</td>\n",
       "      <td>3169.726214</td>\n",
       "      <td>0.493384</td>\n",
       "      <td>3419.082858</td>\n",
       "      <td>9838.670054</td>\n",
       "      <td>6873.820882</td>\n",
       "      <td>128.821330</td>\n",
       "      <td>0.650726</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.005906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>243.311501</td>\n",
       "      <td>286.886047</td>\n",
       "      <td>84.203670</td>\n",
       "      <td>4.139561</td>\n",
       "      <td>934.810112</td>\n",
       "      <td>2699.238260</td>\n",
       "      <td>3154.396287</td>\n",
       "      <td>17.683433</td>\n",
       "      <td>...</td>\n",
       "      <td>3172.721042</td>\n",
       "      <td>0.600036</td>\n",
       "      <td>3427.894935</td>\n",
       "      <td>9857.801675</td>\n",
       "      <td>6897.176659</td>\n",
       "      <td>149.088885</td>\n",
       "      <td>0.864824</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>0.010246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>249.683008</td>\n",
       "      <td>295.040376</td>\n",
       "      <td>86.297021</td>\n",
       "      <td>6.683609</td>\n",
       "      <td>993.912712</td>\n",
       "      <td>2870.020725</td>\n",
       "      <td>3355.033158</td>\n",
       "      <td>28.823944</td>\n",
       "      <td>...</td>\n",
       "      <td>3178.383990</td>\n",
       "      <td>0.754216</td>\n",
       "      <td>3431.645480</td>\n",
       "      <td>9876.338090</td>\n",
       "      <td>6902.651580</td>\n",
       "      <td>166.721030</td>\n",
       "      <td>1.230529</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>0.017021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>343.332039</td>\n",
       "      <td>363.110579</td>\n",
       "      <td>153.377320</td>\n",
       "      <td>179.450603</td>\n",
       "      <td>1406.988962</td>\n",
       "      <td>3519.137976</td>\n",
       "      <td>6352.718183</td>\n",
       "      <td>931.150393</td>\n",
       "      <td>...</td>\n",
       "      <td>3208.904013</td>\n",
       "      <td>809.978737</td>\n",
       "      <td>3439.809082</td>\n",
       "      <td>9924.719835</td>\n",
       "      <td>6931.307546</td>\n",
       "      <td>3947.906297</td>\n",
       "      <td>179.215542</td>\n",
       "      <td>9075.000000</td>\n",
       "      <td>21774.000000</td>\n",
       "      <td>0.462871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             section         cavity  gobdiameteraverage_avg  \\\n",
       "count  239320.000000  239320.000000           239320.000000   \n",
       "mean        5.237155       2.018586              241.217198   \n",
       "std         2.832643       0.815209               13.621712   \n",
       "min         1.000000       1.000000               49.900988   \n",
       "25%         3.000000       1.000000              233.922123   \n",
       "50%         5.000000       2.000000              243.311501   \n",
       "75%         8.000000       3.000000              249.683008   \n",
       "max        10.000000       3.000000              343.332039   \n",
       "\n",
       "       gobdiameteraverage_min  gobdiameteraverage_max  gobdiameteraverage_std  \\\n",
       "count           239320.000000           239320.000000           239320.000000   \n",
       "mean               284.306529               83.505213                5.315899   \n",
       "std                 16.689874                4.672913                5.210246   \n",
       "min                 58.621037               17.333118                0.000000   \n",
       "25%                275.288268               81.055125                2.340674   \n",
       "50%                286.886047               84.203670                4.139561   \n",
       "75%                295.040376               86.297021                6.683609   \n",
       "max                363.110579              153.377320              179.450603   \n",
       "\n",
       "       goblengthaverage_avg  goblengthaverage_min  goblengthaverage_max  \\\n",
       "count         239320.000000         239320.000000         239320.000000   \n",
       "mean             937.774799           2707.030744           3165.014974   \n",
       "std               82.323839            238.759298            279.432126   \n",
       "min               88.396127             98.783256            478.742964   \n",
       "25%              879.416214           2538.554936           2967.742463   \n",
       "50%              934.810112           2699.238260           3154.396287   \n",
       "75%              993.912712           2870.020725           3355.033158   \n",
       "max             1406.988962           3519.137976           6352.718183   \n",
       "\n",
       "       goblengthaverage_std  ...  center_top_tc_max  center_top_tc_std  \\\n",
       "count         239320.000000  ...      239320.000000      239320.000000   \n",
       "mean              24.444875  ...        3172.712382           1.075827   \n",
       "std               38.442730  ...           7.357667          17.973202   \n",
       "min                0.000000  ...        3152.492339           0.000000   \n",
       "25%                9.670093  ...        3169.726214           0.493384   \n",
       "50%               17.683433  ...        3172.721042           0.600036   \n",
       "75%               28.823944  ...        3178.383990           0.754216   \n",
       "max              931.150393  ...        3208.904013         809.978737   \n",
       "\n",
       "       feeder_global_avg  feeder_global_min  feeder_global_max  \\\n",
       "count      239320.000000      239320.000000      239320.000000   \n",
       "mean         3426.013520        9853.180678        6887.666297   \n",
       "std             7.441552         116.776806          19.418643   \n",
       "min          3406.899953        4769.130543        6840.563652   \n",
       "25%          3419.082858        9838.670054        6873.820882   \n",
       "50%          3427.894935        9857.801675        6897.176659   \n",
       "75%          3431.645480        9876.338090        6902.651580   \n",
       "max          3439.809082        9924.719835        6931.307546   \n",
       "\n",
       "       feeder_global_diff_min_max  feeder_global_std  rejected_Sidewall  \\\n",
       "count               239320.000000      239320.000000      239320.000000   \n",
       "mean                   149.092685           1.389070           7.194911   \n",
       "std                     88.065655           4.410788          35.552139   \n",
       "min                     96.631685           0.000000           0.000000   \n",
       "25%                    128.821330           0.650726           2.000000   \n",
       "50%                    149.088885           0.864824           4.000000   \n",
       "75%                    166.721030           1.230529           7.000000   \n",
       "max                   3947.906297         179.215542        9075.000000   \n",
       "\n",
       "       total_Sidewall  perc_defects_Sidewall  \n",
       "count   239320.000000          239320.000000  \n",
       "mean       465.633754               0.014636  \n",
       "std        430.267551               0.018720  \n",
       "min        101.000000               0.000000  \n",
       "25%        420.000000               0.005906  \n",
       "50%        458.000000               0.010246  \n",
       "75%        475.000000               0.017021  \n",
       "max      21774.000000               0.462871  \n",
       "\n",
       "[8 rows x 235 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d049a82-a55c-4e32-b8bf-9f7b7629a0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['initial_time',\n",
       " 'final_time',\n",
       " 'section',\n",
       " 'cavity',\n",
       " 'gobdiameteraverage_avg',\n",
       " 'gobdiameteraverage_min',\n",
       " 'gobdiameteraverage_max',\n",
       " 'gobdiameteraverage_std',\n",
       " 'goblengthaverage_avg',\n",
       " 'goblengthaverage_min',\n",
       " 'goblengthaverage_max',\n",
       " 'goblengthaverage_std',\n",
       " 'gobtimeofarrivalaverage_avg',\n",
       " 'gobtimeofarrivalaverage_min',\n",
       " 'gobtimeofarrivalaverage_max',\n",
       " 'gobtimeofarrivalaverage_std',\n",
       " 'gobxpositionaverage_avg',\n",
       " 'gobxpositionaverage_min',\n",
       " 'gobxpositionaverage_max',\n",
       " 'gobxpositionaverage_std',\n",
       " 'gobypositionaverage_avg',\n",
       " 'gobypositionaverage_min',\n",
       " 'gobypositionaverage_max',\n",
       " 'gobypositionaverage_std',\n",
       " 'gobzspeedaverage_avg',\n",
       " 'gobzspeedaverage_min',\n",
       " 'gobzspeedaverage_max',\n",
       " 'gobzspeedaverage_std',\n",
       " 'warespacingrelativedegreesaverage_avg',\n",
       " 'warespacingrelativedegreesaverage_min',\n",
       " 'warespacingrelativedegreesaverage_max',\n",
       " 'warespacingrelativedegreesaverage_std',\n",
       " 'warespacingrelativepositionaverage_avg',\n",
       " 'warespacingrelativepositionaverage_min',\n",
       " 'warespacingrelativepositionaverage_max',\n",
       " 'warespacingrelativepositionaverage_std',\n",
       " 'warespacingrelativetimeaverage_avg',\n",
       " 'warespacingrelativetimeaverage_min',\n",
       " 'warespacingrelativetimeaverage_max',\n",
       " 'warespacingrelativetimeaverage_std',\n",
       " 'leftblankmiddletemp_avg_avg',\n",
       " 'leftblankmiddletemp_min_min',\n",
       " 'leftblankmiddletemp_max_max',\n",
       " 'leftblankmiddletemp_avg_std',\n",
       " 'neckringlefttemp_avg_avg',\n",
       " 'neckringlefttemp_min_min',\n",
       " 'neckringlefttemp_max_max',\n",
       " 'neckringlefttemp_avg_std',\n",
       " 'plungertoptemp_avg_avg',\n",
       " 'plungertoptemp_min_min',\n",
       " 'plungertoptemp_max_max',\n",
       " 'plungertoptemp_avg_std',\n",
       " 'rightblankmiddletemp_avg_avg',\n",
       " 'rightblankmiddletemp_min_min',\n",
       " 'rightblankmiddletemp_max_max',\n",
       " 'rightblankmiddletemp_avg_std',\n",
       " 'counter_blow_duration_avg',\n",
       " 'counter_blow_duration_min',\n",
       " 'counter_blow_duration_max',\n",
       " 'counter_blow_duration_std',\n",
       " 'deadplate_cooling_duration_avg',\n",
       " 'deadplate_cooling_duration_min',\n",
       " 'deadplate_cooling_duration_max',\n",
       " 'deadplate_cooling_duration_std',\n",
       " 'plunger_cooling_duration_avg',\n",
       " 'plunger_cooling_duration_min',\n",
       " 'plunger_cooling_duration_max',\n",
       " 'plunger_cooling_duration_std',\n",
       " 'plunger_down_duration_avg',\n",
       " 'plunger_down_duration_min',\n",
       " 'plunger_down_duration_max',\n",
       " 'plunger_down_duration_std',\n",
       " 'plunger_up_duration_avg',\n",
       " 'plunger_up_duration_min',\n",
       " 'plunger_up_duration_max',\n",
       " 'plunger_up_duration_std',\n",
       " 'num_interventions',\n",
       " 'blank_cool_calibrated_pressure_avg',\n",
       " 'blank_cool_calibrated_pressure_min',\n",
       " 'blank_cool_calibrated_pressure_max',\n",
       " 'blank_cool_calibrated_pressure_std',\n",
       " 'blank_cool_calibrated_temp_avg',\n",
       " 'blank_cool_calibrated_temp_min',\n",
       " 'blank_cool_calibrated_temp_max',\n",
       " 'blank_cool_calibrated_temp_std',\n",
       " 'blank_cool_compensated_sp_avg',\n",
       " 'blank_cool_compensated_sp_min',\n",
       " 'blank_cool_compensated_sp_max',\n",
       " 'blank_cool_compensated_sp_std',\n",
       " 'blank_cool_pid_out_avg',\n",
       " 'blank_cool_pid_out_min',\n",
       " 'blank_cool_pid_out_max',\n",
       " 'blank_cool_pid_out_std',\n",
       " 'blank_cool_pid_pv_avg',\n",
       " 'blank_cool_pid_pv_min',\n",
       " 'blank_cool_pid_pv_max',\n",
       " 'blank_cool_pid_pv_std',\n",
       " 'blank_cool_pid_sp_avg',\n",
       " 'blank_cool_pid_sp_min',\n",
       " 'blank_cool_pid_sp_max',\n",
       " 'blank_cool_pid_sp_std',\n",
       " 'blank_cool_pressure_out_avg',\n",
       " 'blank_cool_pressure_out_min',\n",
       " 'blank_cool_pressure_out_max',\n",
       " 'blank_cool_pressure_out_std',\n",
       " 'blank_cool_pressure_pv_avg',\n",
       " 'blank_cool_pressure_pv_min',\n",
       " 'blank_cool_pressure_pv_max',\n",
       " 'blank_cool_pressure_pv_std',\n",
       " 'conveyorspeed_avg',\n",
       " 'conveyorspeed_min',\n",
       " 'conveyorspeed_max',\n",
       " 'conveyorspeed_std',\n",
       " 'crossconveyortrimfactor_avg',\n",
       " 'crossconveyortrimfactor_min',\n",
       " 'crossconveyortrimfactor_max',\n",
       " 'crossconveyortrimfactor_std',\n",
       " 'dead_conv_cool_calibrated_pressure_avg',\n",
       " 'dead_conv_cool_calibrated_pressure_min',\n",
       " 'dead_conv_cool_calibrated_pressure_max',\n",
       " 'dead_conv_cool_calibrated_pressure_std',\n",
       " 'dead_conv_cool_calibrated_temp_avg',\n",
       " 'dead_conv_cool_calibrated_temp_min',\n",
       " 'dead_conv_cool_calibrated_temp_max',\n",
       " 'dead_conv_cool_calibrated_temp_std',\n",
       " 'dead_conv_cool_compensated_sp_avg',\n",
       " 'dead_conv_cool_compensated_sp_min',\n",
       " 'dead_conv_cool_compensated_sp_max',\n",
       " 'dead_conv_cool_compensated_sp_std',\n",
       " 'dead_conv_cool_pid_out_avg',\n",
       " 'dead_conv_cool_pid_out_min',\n",
       " 'dead_conv_cool_pid_out_max',\n",
       " 'dead_conv_cool_pid_out_std',\n",
       " 'dead_conv_cool_pid_pv_avg',\n",
       " 'dead_conv_cool_pid_pv_min',\n",
       " 'dead_conv_cool_pid_pv_max',\n",
       " 'dead_conv_cool_pid_pv_std',\n",
       " 'dead_conv_cool_pid_sp_avg',\n",
       " 'dead_conv_cool_pid_sp_min',\n",
       " 'dead_conv_cool_pid_sp_max',\n",
       " 'dead_conv_cool_pid_sp_std',\n",
       " 'dead_conv_cool_pressure_out_avg',\n",
       " 'dead_conv_cool_pressure_out_min',\n",
       " 'dead_conv_cool_pressure_out_max',\n",
       " 'dead_conv_cool_pressure_out_std',\n",
       " 'dead_conv_cool_pressure_pv_avg',\n",
       " 'dead_conv_cool_pressure_pv_min',\n",
       " 'dead_conv_cool_pressure_pv_max',\n",
       " 'dead_conv_cool_pressure_pv_std',\n",
       " 'feederplungerheight_avg',\n",
       " 'feederplungerheight_min',\n",
       " 'feederplungerheight_max',\n",
       " 'feederplungerheight_std',\n",
       " 'feederplungerstroke_avg',\n",
       " 'feederplungerstroke_min',\n",
       " 'feederplungerstroke_max',\n",
       " 'feederplungerstroke_std',\n",
       " 'mold_cool_calibrated_pressure_avg',\n",
       " 'mold_cool_calibrated_pressure_min',\n",
       " 'mold_cool_calibrated_pressure_max',\n",
       " 'mold_cool_calibrated_pressure_std',\n",
       " 'mold_cool_calibrated_temp_avg',\n",
       " 'mold_cool_calibrated_temp_min',\n",
       " 'mold_cool_calibrated_temp_max',\n",
       " 'mold_cool_calibrated_temp_std',\n",
       " 'mold_cool_compensated_sp_avg',\n",
       " 'mold_cool_compensated_sp_min',\n",
       " 'mold_cool_compensated_sp_max',\n",
       " 'mold_cool_compensated_sp_std',\n",
       " 'mold_cool_pid_out_avg',\n",
       " 'mold_cool_pid_out_min',\n",
       " 'mold_cool_pid_out_max',\n",
       " 'mold_cool_pid_out_std',\n",
       " 'mold_cool_pid_pv_avg',\n",
       " 'mold_cool_pid_pv_min',\n",
       " 'mold_cool_pid_pv_max',\n",
       " 'mold_cool_pid_pv_std',\n",
       " 'mold_cool_pid_sp_avg',\n",
       " 'mold_cool_pid_sp_min',\n",
       " 'mold_cool_pid_sp_max',\n",
       " 'mold_cool_pid_sp_std',\n",
       " 'mold_cool_pressure_out_avg',\n",
       " 'mold_cool_pressure_out_min',\n",
       " 'mold_cool_pressure_out_max',\n",
       " 'mold_cool_pressure_out_std',\n",
       " 'mold_cool_pressure_pv_avg',\n",
       " 'mold_cool_pressure_pv_min',\n",
       " 'mold_cool_pressure_pv_max',\n",
       " 'mold_cool_pressure_pv_std',\n",
       " 'mold_cool_temp_pv_avg',\n",
       " 'mold_cool_temp_pv_min',\n",
       " 'mold_cool_temp_pv_max',\n",
       " 'mold_cool_temp_pv_std',\n",
       " 'tubeheight_avg',\n",
       " 'tubeheight_min',\n",
       " 'tubeheight_max',\n",
       " 'tubeheight_std',\n",
       " 'tuberotationspeed_avg',\n",
       " 'tuberotationspeed_min',\n",
       " 'tuberotationspeed_max',\n",
       " 'tuberotationspeed_std',\n",
       " 'counterblowplungercoolpressure_avg',\n",
       " 'counterblowplungercoolpressure_min',\n",
       " 'counterblowplungercoolpressure_max',\n",
       " 'counterblowplungercoolpressure_std',\n",
       " 'finalblowpressure_avg',\n",
       " 'finalblowpressure_min',\n",
       " 'finalblowpressure_max',\n",
       " 'finalblowpressure_std',\n",
       " 'finishcoolingpressure_avg',\n",
       " 'finishcoolingpressure_min',\n",
       " 'finishcoolingpressure_max',\n",
       " 'finishcoolingpressure_std',\n",
       " 'pilotairpressure_avg',\n",
       " 'pilotairpressure_min',\n",
       " 'pilotairpressure_max',\n",
       " 'pilotairpressure_std',\n",
       " 'settleblowpressure_avg',\n",
       " 'settleblowpressure_min',\n",
       " 'settleblowpressure_max',\n",
       " 'settleblowpressure_std',\n",
       " 'vacuumpressure_avg',\n",
       " 'vacuumpressure_min',\n",
       " 'vacuumpressure_max',\n",
       " 'vacuumpressure_std',\n",
       " 'reference',\n",
       " 'production',\n",
       " 'center_top_tc_avg',\n",
       " 'center_top_tc_min',\n",
       " 'center_top_tc_max',\n",
       " 'center_top_tc_std',\n",
       " 'feeder_global_avg',\n",
       " 'feeder_global_min',\n",
       " 'feeder_global_max',\n",
       " 'feeder_global_diff_min_max',\n",
       " 'feeder_global_std',\n",
       " 'rejected_Sidewall',\n",
       " 'total_Sidewall',\n",
       " 'perc_defects_Sidewall']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d207bfd-9672-46f9-b433-37dfadd0bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = raw_data.isnull().sum()\n",
    "for item in missing:\n",
    "    if item > 0:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7ed5cfe-8516-448b-8777-600a55c13437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_time</th>\n",
       "      <th>final_time</th>\n",
       "      <th>section</th>\n",
       "      <th>cavity</th>\n",
       "      <th>gobdiameteraverage_avg</th>\n",
       "      <th>gobdiameteraverage_min</th>\n",
       "      <th>gobdiameteraverage_max</th>\n",
       "      <th>gobdiameteraverage_std</th>\n",
       "      <th>goblengthaverage_avg</th>\n",
       "      <th>goblengthaverage_min</th>\n",
       "      <th>...</th>\n",
       "      <th>center_top_tc_max</th>\n",
       "      <th>center_top_tc_std</th>\n",
       "      <th>feeder_global_avg</th>\n",
       "      <th>feeder_global_min</th>\n",
       "      <th>feeder_global_max</th>\n",
       "      <th>feeder_global_diff_min_max</th>\n",
       "      <th>feeder_global_std</th>\n",
       "      <th>rejected_Sidewall</th>\n",
       "      <th>total_Sidewall</th>\n",
       "      <th>perc_defects_Sidewall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115040</th>\n",
       "      <td>2023-04-28 17:40:00</td>\n",
       "      <td>2023-04-28 19:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>243.336766</td>\n",
       "      <td>286.589105</td>\n",
       "      <td>84.390129</td>\n",
       "      <td>4.259227</td>\n",
       "      <td>973.693245</td>\n",
       "      <td>2817.212621</td>\n",
       "      <td>...</td>\n",
       "      <td>3165.179520</td>\n",
       "      <td>0.959701</td>\n",
       "      <td>3419.260846</td>\n",
       "      <td>9848.533468</td>\n",
       "      <td>6875.684684</td>\n",
       "      <td>139.613960</td>\n",
       "      <td>1.415816</td>\n",
       "      <td>13.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>0.029613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30121</th>\n",
       "      <td>2023-08-01 08:20:00</td>\n",
       "      <td>2023-08-01 09:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>234.327265</td>\n",
       "      <td>277.983532</td>\n",
       "      <td>80.678449</td>\n",
       "      <td>2.834064</td>\n",
       "      <td>890.433315</td>\n",
       "      <td>2566.966404</td>\n",
       "      <td>...</td>\n",
       "      <td>3172.693817</td>\n",
       "      <td>0.410639</td>\n",
       "      <td>3429.176022</td>\n",
       "      <td>9846.917908</td>\n",
       "      <td>6906.903380</td>\n",
       "      <td>174.439015</td>\n",
       "      <td>2.373998</td>\n",
       "      <td>3.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>0.007426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69423</th>\n",
       "      <td>2023-08-26 05:00:00</td>\n",
       "      <td>2023-08-26 06:20:00</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>232.775384</td>\n",
       "      <td>275.188959</td>\n",
       "      <td>80.353634</td>\n",
       "      <td>12.504765</td>\n",
       "      <td>986.271377</td>\n",
       "      <td>2840.131725</td>\n",
       "      <td>...</td>\n",
       "      <td>3172.911622</td>\n",
       "      <td>0.912278</td>\n",
       "      <td>3428.550911</td>\n",
       "      <td>9855.250792</td>\n",
       "      <td>6905.738503</td>\n",
       "      <td>167.034769</td>\n",
       "      <td>1.241025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>0.003185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39015</th>\n",
       "      <td>2023-03-26 05:20:00</td>\n",
       "      <td>2023-03-26 06:40:00</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>234.373496</td>\n",
       "      <td>275.823033</td>\n",
       "      <td>81.759759</td>\n",
       "      <td>4.555500</td>\n",
       "      <td>1002.747913</td>\n",
       "      <td>2897.949693</td>\n",
       "      <td>...</td>\n",
       "      <td>3172.557688</td>\n",
       "      <td>0.520755</td>\n",
       "      <td>3418.172404</td>\n",
       "      <td>9812.395961</td>\n",
       "      <td>6861.414945</td>\n",
       "      <td>150.908572</td>\n",
       "      <td>1.038706</td>\n",
       "      <td>5.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0.010526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28502</th>\n",
       "      <td>2023-07-25 21:40:00</td>\n",
       "      <td>2023-07-25 23:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>231.374113</td>\n",
       "      <td>272.945029</td>\n",
       "      <td>79.994509</td>\n",
       "      <td>3.093841</td>\n",
       "      <td>1000.008348</td>\n",
       "      <td>2900.645822</td>\n",
       "      <td>...</td>\n",
       "      <td>3175.579742</td>\n",
       "      <td>0.627845</td>\n",
       "      <td>3430.729719</td>\n",
       "      <td>9862.903441</td>\n",
       "      <td>6904.515382</td>\n",
       "      <td>160.069758</td>\n",
       "      <td>0.693045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.002525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               initial_time           final_time  section  cavity  \\\n",
       "115040  2023-04-28 17:40:00  2023-04-28 19:00:00        7       3   \n",
       "30121   2023-08-01 08:20:00  2023-08-01 09:40:00        1       1   \n",
       "69423   2023-08-26 05:00:00  2023-08-26 06:20:00        4       3   \n",
       "39015   2023-03-26 05:20:00  2023-03-26 06:40:00        4       3   \n",
       "28502   2023-07-25 21:40:00  2023-07-25 23:00:00        2       3   \n",
       "\n",
       "        gobdiameteraverage_avg  gobdiameteraverage_min  \\\n",
       "115040              243.336766              286.589105   \n",
       "30121               234.327265              277.983532   \n",
       "69423               232.775384              275.188959   \n",
       "39015               234.373496              275.823033   \n",
       "28502               231.374113              272.945029   \n",
       "\n",
       "        gobdiameteraverage_max  gobdiameteraverage_std  goblengthaverage_avg  \\\n",
       "115040               84.390129                4.259227            973.693245   \n",
       "30121                80.678449                2.834064            890.433315   \n",
       "69423                80.353634               12.504765            986.271377   \n",
       "39015                81.759759                4.555500           1002.747913   \n",
       "28502                79.994509                3.093841           1000.008348   \n",
       "\n",
       "        goblengthaverage_min  ...  center_top_tc_max  center_top_tc_std  \\\n",
       "115040           2817.212621  ...        3165.179520           0.959701   \n",
       "30121            2566.966404  ...        3172.693817           0.410639   \n",
       "69423            2840.131725  ...        3172.911622           0.912278   \n",
       "39015            2897.949693  ...        3172.557688           0.520755   \n",
       "28502            2900.645822  ...        3175.579742           0.627845   \n",
       "\n",
       "        feeder_global_avg  feeder_global_min  feeder_global_max  \\\n",
       "115040        3419.260846        9848.533468        6875.684684   \n",
       "30121         3429.176022        9846.917908        6906.903380   \n",
       "69423         3428.550911        9855.250792        6905.738503   \n",
       "39015         3418.172404        9812.395961        6861.414945   \n",
       "28502         3430.729719        9862.903441        6904.515382   \n",
       "\n",
       "        feeder_global_diff_min_max  feeder_global_std  rejected_Sidewall  \\\n",
       "115040                  139.613960           1.415816               13.0   \n",
       "30121                   174.439015           2.373998                3.0   \n",
       "69423                   167.034769           1.241025                1.0   \n",
       "39015                   150.908572           1.038706                5.0   \n",
       "28502                   160.069758           0.693045                1.0   \n",
       "\n",
       "        total_Sidewall  perc_defects_Sidewall  \n",
       "115040           439.0               0.029613  \n",
       "30121            404.0               0.007426  \n",
       "69423            314.0               0.003185  \n",
       "39015            475.0               0.010526  \n",
       "28502            396.0               0.002525  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = raw_data.sample(3000, random_state=1)\n",
    "data_sample.shape\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501b4d5",
   "metadata": {},
   "source": [
    "# Split and Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3671119",
   "metadata": {},
   "source": [
    "First we created a new column called \"Defects\". It is a binary classefier, which signals if a bottle is defect or not. This is determined by the defect rate. If it is above 0.02 it is defective and gets a 1 and vice versa. Then we create a holdout dataset in order to test out of sample performance for the final model. Furthermore we upsample or data based on \"Defects\" in order to create a balanced dataset. This dataset is then furthermore split into a test and train dataset with a 0.2/0.8 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e82af7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/048sbrkd4k5f7y4yw3rstw7m0000gn/T/ipykernel_67380/333874530.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  class_0 = non_holdout_data[data_set['Defects'] == 0]\n",
      "/var/folders/cr/048sbrkd4k5f7y4yw3rstw7m0000gn/T/ipykernel_67380/333874530.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  class_1 = non_holdout_data[data_set['Defects'] == 1]\n"
     ]
    }
   ],
   "source": [
    "data_set = raw_data\n",
    "\n",
    "#create binary outcome variable for defect = 1 and not defect = 0 with threshold of 2%\n",
    "threshold = 0.02\n",
    "data_set['Defects'] = (data_set.iloc[:, -1] > threshold).astype(int)\n",
    "\n",
    "\n",
    "# Creating Holdout\n",
    "non_holdout_data, holdout_data = train_test_split(data_set, test_size=0.1, random_state=5, stratify=data_set['Defects'])\n",
    "\n",
    "\n",
    "# Upsample class 1\n",
    "class_0 = non_holdout_data[data_set['Defects'] == 0]\n",
    "class_1 = non_holdout_data[data_set['Defects'] == 1]\n",
    "class_1_upsampled = class_1.sample(n=len(class_0), replace=True, random_state=5)  # Enable replacement to upsample\n",
    "\n",
    "# Combine back the upsampled class 1 with class 0\n",
    "balanced_data = pd.concat([class_0, class_1_upsampled])\n",
    "\n",
    "#Split the Dataset\n",
    "train_data, test_data = train_test_split(balanced_data, test_size=0.2, random_state=5, stratify=balanced_data['Defects'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c38d3",
   "metadata": {},
   "source": [
    "# Transform Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042bbb31",
   "metadata": {},
   "source": [
    "We split the dataset columns into features and targets. In our case target is \"Defects\" and \"perc_defects_Sidewall\", the rest are considered features. Intial time and final time are substracted from each other to gain the duration of the process and another column is created to accomodate this feature. Unessecary features are droped. This process is repeated for the holdoutdata, test data and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "466d0a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279489, 233)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#split dataset in features_train and outcome \n",
    "features_train = train_data.iloc[:, :-2] \n",
    "target_reg_train = train_data.iloc[:, -2] \n",
    "target_cat_train = train_data.iloc[:, -1] \n",
    "\n",
    "#convert target to categorical\n",
    "#target1r =\n",
    "#target2r =\n",
    "target_cat_train = to_categorical(target_cat_train)\n",
    "\n",
    "#Handle Timestamps in features dataset\n",
    "# Convert initial_time and final_time to datetime, and create a new feature 'duration'\n",
    "features_train['initial_time'] = pd.to_datetime(features_train['initial_time'])\n",
    "features_train['final_time'] = pd.to_datetime(features_train['final_time'])\n",
    "features_train['duration'] = (features_train['final_time'] - features_train['initial_time']).dt.total_seconds() / 60.0  # duration in minutes\n",
    "\n",
    "#drop not needed features\n",
    "features_train = features_train.drop(['initial_time', 'final_time', 'reference', 'production', 'rejected_Sidewall', 'total_Sidewall'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3055a1",
   "metadata": {},
   "source": [
    "# Transform Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "342b7653-cd34-47c2-a1c4-6272ec64b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69873, 233)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_set.iloc[:, -1] = (data_set.iloc[:, -1] > threshold).astype(int)\n",
    "# data_set.rename(columns={'perc_defects_Sidewall': 'Defects'}, inplace=True)\n",
    "\n",
    "#split dataset in features and outcome \n",
    "features_test = test_data.iloc[:, :-2]  # All rows, all columns except the last one\n",
    "target_reg_test = test_data.iloc[:, -2] \n",
    "target_cat_test = test_data.iloc[:, -1] \n",
    "\n",
    "#convert target to categorical\n",
    "#target1r =\n",
    "#target2r =\n",
    "target_cat_test = to_categorical(target_cat_test)\n",
    "\n",
    "#Handle Timestamps in features dataset\n",
    "# Convert initial_time and final_time to datetime, and create a new feature 'duration'\n",
    "features_test['initial_time'] = pd.to_datetime(features_test['initial_time'])\n",
    "features_test['final_time'] = pd.to_datetime(features_test['final_time'])\n",
    "features_test['duration'] = (features_test['final_time'] - features_test['initial_time']).dt.total_seconds() / 60.0  # duration in minutes\n",
    "\n",
    "#drop not needed features\n",
    "features_test = features_test.drop(['initial_time', 'final_time', 'reference', 'production', 'rejected_Sidewall', 'total_Sidewall'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "features_test = scaler.fit_transform(features_test)\n",
    "\n",
    "features_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d85afe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dca3aa4",
   "metadata": {},
   "source": [
    "# Transform Holdout Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64d332fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23932, 233)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_set.iloc[:, -1] = (data_set.iloc[:, -1] > threshold).astype(int)\n",
    "# data_set.rename(columns={'perc_defects_Sidewall': 'Defects'}, inplace=True)\n",
    "\n",
    "#split dataset in features and outcome \n",
    "features_holdout = holdout_data.iloc[:, :-2]  # All rows, all columns except the last one\n",
    "target_reg_holdout = holdout_data.iloc[:, -2] \n",
    "target_cat_holdout = holdout_data.iloc[:, -1] \n",
    "\n",
    "#convert target to categorical\n",
    "#target1r =\n",
    "#target2r =\n",
    "target_cat_holdout = to_categorical(target_cat_holdout)\n",
    "\n",
    "#Handle Timestamps in features dataset\n",
    "# Convert initial_time and final_time to datetime, and create a new feature 'duration'\n",
    "features_holdout['initial_time'] = pd.to_datetime(features_holdout['initial_time'])\n",
    "features_holdout['final_time'] = pd.to_datetime(features_holdout['final_time'])\n",
    "features_holdout['duration'] = (features_holdout['final_time'] - features_holdout['initial_time']).dt.total_seconds() / 60.0  # duration in minutes\n",
    "\n",
    "#drop not needed features\n",
    "features_holdout = features_holdout.drop(['initial_time', 'final_time', 'reference', 'production', 'rejected_Sidewall', 'total_Sidewall'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "features_holdout = scaler.fit_transform(features_holdout)\n",
    "\n",
    "features_holdout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb2e46",
   "metadata": {},
   "source": [
    "# Model Definition and Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1ba3a8",
   "metadata": {},
   "source": [
    "First, a base model is created using the Sequential API. This model consists of three dense layers with 'relu' activation, a batch normalization layer, and a dropout layer. The input shape for the first layer is 233.\n",
    "\n",
    "An input layer is then created with the same shape as the base model. The base model is applied to this input to get an intermediate output.\n",
    "\n",
    "Two output layers are defined: a regression output with one neuron and 'relu' activation, and a categorical output with two neurons and 'softmax' activation.\n",
    "\n",
    "A model is created with the defined input and the two outputs. This model is compiled with the Stochastic Gradient Descent (SGD) optimizer. Different loss functions are used for the two outputs: mean squared error for the regression output and categorical cross-entropy for the categorical output. Metrics for evaluation are also defined for each output.\n",
    "\n",
    "Early stopping is set up to monitor the validation loss and stop training when it doesn't improve after 7 epochs. The learning rate is reduced by a factor of 0.1 if no improvement is seen after 3 epochs.\n",
    "\n",
    "Finally, the model is trained on the training data for a maximum of 100 epochs with a batch size of 128. The model validation is done on 20% of the training data. The early stopping and learning rate reduction are applied during training. The training history is stored in a variable.\n",
    "\n",
    "This step is repeated over the other models only with a different optimizer, which is adam and a model architecture that incorporates BatchNormalization after every Dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5eb0ff",
   "metadata": {},
   "source": [
    "## Model with SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "106c39e4-e47a-466d-83fa-9b292a9351fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "2024-05-28 23:49:15.485683: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.6510 - regression_output_loss: 0.0027 - categorical_output_loss: 0.6483 - regression_output_mse: 0.0027 - categorical_output_accuracy: 0.6233 - categorical_output_auc: 0.6732 - val_loss: 0.6156 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.6142 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.6575 - val_categorical_output_auc: 0.7208 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.6104 - regression_output_loss: 0.0014 - categorical_output_loss: 0.6090 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.6632 - categorical_output_auc: 0.7269 - val_loss: 0.5957 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5943 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.6773 - val_categorical_output_auc: 0.7465 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.5923 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5909 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.6810 - categorical_output_auc: 0.7494 - val_loss: 0.5798 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5784 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.6936 - val_categorical_output_auc: 0.7659 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.5775 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5761 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.6952 - categorical_output_auc: 0.7664 - val_loss: 0.5654 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5640 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7059 - val_categorical_output_auc: 0.7796 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.5635 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5622 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7073 - categorical_output_auc: 0.7810 - val_loss: 0.5512 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5499 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7189 - val_categorical_output_auc: 0.7940 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.5503 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5489 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7175 - categorical_output_auc: 0.7938 - val_loss: 0.5398 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5384 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7285 - val_categorical_output_auc: 0.8062 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.5377 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5363 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7273 - categorical_output_auc: 0.8055 - val_loss: 0.5275 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5261 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7368 - val_categorical_output_auc: 0.8154 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.5269 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5256 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7350 - categorical_output_auc: 0.8149 - val_loss: 0.5163 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5149 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7450 - val_categorical_output_auc: 0.8249 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.5151 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5137 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7432 - categorical_output_auc: 0.8248 - val_loss: 0.5057 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5044 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7537 - val_categorical_output_auc: 0.8338 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.5042 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5028 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7522 - categorical_output_auc: 0.8338 - val_loss: 0.4956 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4942 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7611 - val_categorical_output_auc: 0.8414 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4940 - regression_output_loss: 0.0014 - categorical_output_loss: 0.4926 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7590 - categorical_output_auc: 0.8413 - val_loss: 0.4864 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4850 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7680 - val_categorical_output_auc: 0.8489 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4845 - regression_output_loss: 0.0014 - categorical_output_loss: 0.4831 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7666 - categorical_output_auc: 0.8487 - val_loss: 0.4789 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4775 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7709 - val_categorical_output_auc: 0.8537 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4746 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4733 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7731 - categorical_output_auc: 0.8555 - val_loss: 0.4695 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4681 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7795 - val_categorical_output_auc: 0.8612 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4676 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4663 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7771 - categorical_output_auc: 0.8603 - val_loss: 0.4609 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4595 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7842 - val_categorical_output_auc: 0.8655 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4584 - regression_output_loss: 0.0014 - categorical_output_loss: 0.4570 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7839 - categorical_output_auc: 0.8666 - val_loss: 0.4578 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4565 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7845 - val_categorical_output_auc: 0.8668 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4511 - regression_output_loss: 0.0014 - categorical_output_loss: 0.4497 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7881 - categorical_output_auc: 0.8712 - val_loss: 0.4475 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4461 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7932 - val_categorical_output_auc: 0.8740 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4439 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4426 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7915 - categorical_output_auc: 0.8755 - val_loss: 0.4418 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4404 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7961 - val_categorical_output_auc: 0.8783 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4387 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4374 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7950 - categorical_output_auc: 0.8790 - val_loss: 0.4351 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4337 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7989 - val_categorical_output_auc: 0.8817 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4305 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4292 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7994 - categorical_output_auc: 0.8836 - val_loss: 0.4300 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4286 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8035 - val_categorical_output_auc: 0.8845 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4252 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4239 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8032 - categorical_output_auc: 0.8868 - val_loss: 0.4267 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4253 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8063 - val_categorical_output_auc: 0.8863 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4183 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4170 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8072 - categorical_output_auc: 0.8906 - val_loss: 0.4203 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4189 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8071 - val_categorical_output_auc: 0.8906 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4142 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4129 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8095 - categorical_output_auc: 0.8930 - val_loss: 0.4122 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4108 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8149 - val_categorical_output_auc: 0.8957 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4082 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4069 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8127 - categorical_output_auc: 0.8964 - val_loss: 0.4110 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4096 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8129 - val_categorical_output_auc: 0.8956 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.4027 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4014 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8161 - categorical_output_auc: 0.8994 - val_loss: 0.4031 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4017 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8180 - val_categorical_output_auc: 0.8996 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.3985 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3972 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8183 - categorical_output_auc: 0.9015 - val_loss: 0.4043 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4029 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8187 - val_categorical_output_auc: 0.8995 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.3937 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3924 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8202 - categorical_output_auc: 0.9039 - val_loss: 0.4012 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3999 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8195 - val_categorical_output_auc: 0.9001 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.3896 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3883 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8229 - categorical_output_auc: 0.9061 - val_loss: 0.3960 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3947 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8244 - val_categorical_output_auc: 0.9040 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.3843 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3829 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8270 - categorical_output_auc: 0.9090 - val_loss: 0.3922 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3908 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8256 - val_categorical_output_auc: 0.9054 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3794 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3781 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8290 - categorical_output_auc: 0.9113 - val_loss: 0.3865 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3851 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8299 - val_categorical_output_auc: 0.9086 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.3754 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3740 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8318 - categorical_output_auc: 0.9134 - val_loss: 0.3835 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3821 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8296 - val_categorical_output_auc: 0.9101 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.3718 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3705 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8329 - categorical_output_auc: 0.9150 - val_loss: 0.3793 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3779 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8349 - val_categorical_output_auc: 0.9120 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1747/1747 [==============================] - 3s 1ms/step - loss: 0.3676 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3662 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8350 - categorical_output_auc: 0.9169 - val_loss: 0.3786 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3773 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8327 - val_categorical_output_auc: 0.9123 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3635 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3622 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8377 - categorical_output_auc: 0.9189 - val_loss: 0.3753 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3740 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8345 - val_categorical_output_auc: 0.9138 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3608 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3595 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8392 - categorical_output_auc: 0.9201 - val_loss: 0.3738 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3724 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8369 - val_categorical_output_auc: 0.9148 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3585 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3571 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8405 - categorical_output_auc: 0.9213 - val_loss: 0.3677 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3663 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8390 - val_categorical_output_auc: 0.9176 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3534 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3520 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8427 - categorical_output_auc: 0.9236 - val_loss: 0.3644 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3631 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8416 - val_categorical_output_auc: 0.9193 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3496 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3483 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8451 - categorical_output_auc: 0.9253 - val_loss: 0.3644 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3630 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8423 - val_categorical_output_auc: 0.9195 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3475 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3462 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8459 - categorical_output_auc: 0.9261 - val_loss: 0.3574 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3560 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8454 - val_categorical_output_auc: 0.9227 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3436 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3423 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8481 - categorical_output_auc: 0.9278 - val_loss: 0.3572 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3558 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8468 - val_categorical_output_auc: 0.9227 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3411 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3397 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8487 - categorical_output_auc: 0.9291 - val_loss: 0.3668 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3654 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8388 - val_categorical_output_auc: 0.9183 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3389 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3376 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8501 - categorical_output_auc: 0.9299 - val_loss: 0.3610 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3596 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8458 - val_categorical_output_auc: 0.9212 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3368 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3355 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8518 - categorical_output_auc: 0.9307 - val_loss: 0.3533 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3519 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8464 - val_categorical_output_auc: 0.9245 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3345 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3332 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8521 - categorical_output_auc: 0.9317 - val_loss: 0.3455 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3442 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8506 - val_categorical_output_auc: 0.9277 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3306 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3293 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8549 - categorical_output_auc: 0.9335 - val_loss: 0.3516 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3502 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8493 - val_categorical_output_auc: 0.9255 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3293 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3279 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8553 - categorical_output_auc: 0.9340 - val_loss: 0.3451 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3438 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8513 - val_categorical_output_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3249 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3236 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8579 - categorical_output_auc: 0.9358 - val_loss: 0.3479 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3465 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8522 - val_categorical_output_auc: 0.9269 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3248 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3235 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8584 - categorical_output_auc: 0.9358 - val_loss: 0.3406 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3392 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8545 - val_categorical_output_auc: 0.9298 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3215 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3202 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8592 - categorical_output_auc: 0.9371 - val_loss: 0.3400 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3386 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8562 - val_categorical_output_auc: 0.9301 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3197 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3184 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8602 - categorical_output_auc: 0.9380 - val_loss: 0.3424 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3410 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8538 - val_categorical_output_auc: 0.9292 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3180 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3166 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8621 - categorical_output_auc: 0.9386 - val_loss: 0.3354 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3340 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8582 - val_categorical_output_auc: 0.9324 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3146 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3132 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8632 - categorical_output_auc: 0.9399 - val_loss: 0.3356 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3342 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8577 - val_categorical_output_auc: 0.9323 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3138 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3125 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8630 - categorical_output_auc: 0.9402 - val_loss: 0.3385 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3371 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8558 - val_categorical_output_auc: 0.9310 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3106 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3093 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8647 - categorical_output_auc: 0.9414 - val_loss: 0.3311 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3297 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8596 - val_categorical_output_auc: 0.9342 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3101 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3088 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8651 - categorical_output_auc: 0.9416 - val_loss: 0.3296 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3282 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8619 - val_categorical_output_auc: 0.9348 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3071 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3057 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8663 - categorical_output_auc: 0.9428 - val_loss: 0.3395 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3381 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8574 - val_categorical_output_auc: 0.9308 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3056 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3043 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8674 - categorical_output_auc: 0.9433 - val_loss: 0.3300 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3286 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8615 - val_categorical_output_auc: 0.9347 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3027 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3014 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8690 - categorical_output_auc: 0.9445 - val_loss: 0.3241 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3228 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8643 - val_categorical_output_auc: 0.9372 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3005 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2992 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8694 - categorical_output_auc: 0.9452 - val_loss: 0.3283 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3269 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8622 - val_categorical_output_auc: 0.9357 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2987 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2974 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8705 - categorical_output_auc: 0.9459 - val_loss: 0.3251 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3238 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8627 - val_categorical_output_auc: 0.9368 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2981 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2967 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8715 - categorical_output_auc: 0.9462 - val_loss: 0.3237 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3223 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8642 - val_categorical_output_auc: 0.9374 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "1747/1747 [==============================] - 4s 2ms/step - loss: 0.2966 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2953 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8722 - categorical_output_auc: 0.9468 - val_loss: 0.3232 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3219 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8666 - val_categorical_output_auc: 0.9376 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2942 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2929 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8735 - categorical_output_auc: 0.9476 - val_loss: 0.3145 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3131 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8687 - val_categorical_output_auc: 0.9409 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2938 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2924 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8731 - categorical_output_auc: 0.9478 - val_loss: 0.3201 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3188 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8674 - val_categorical_output_auc: 0.9389 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2917 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2904 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8736 - categorical_output_auc: 0.9485 - val_loss: 0.3227 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3213 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8658 - val_categorical_output_auc: 0.9383 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2905 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2892 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8747 - categorical_output_auc: 0.9490 - val_loss: 0.3161 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3147 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8698 - val_categorical_output_auc: 0.9404 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2634 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2621 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8884 - categorical_output_auc: 0.9585 - val_loss: 0.2972 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2958 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8802 - val_categorical_output_auc: 0.9476 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2561 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2548 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8921 - categorical_output_auc: 0.9608 - val_loss: 0.2958 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2945 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8796 - val_categorical_output_auc: 0.9481 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2537 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2524 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8923 - categorical_output_auc: 0.9616 - val_loss: 0.2951 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2938 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8812 - val_categorical_output_auc: 0.9484 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2527 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2513 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8928 - categorical_output_auc: 0.9618 - val_loss: 0.2927 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2914 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8819 - val_categorical_output_auc: 0.9492 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2518 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2505 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8937 - categorical_output_auc: 0.9621 - val_loss: 0.2924 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2910 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8822 - val_categorical_output_auc: 0.9493 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2514 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2501 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8946 - categorical_output_auc: 0.9623 - val_loss: 0.2913 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2899 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8837 - val_categorical_output_auc: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2504 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2491 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8942 - categorical_output_auc: 0.9625 - val_loss: 0.2909 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2896 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8833 - val_categorical_output_auc: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2496 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2482 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8945 - categorical_output_auc: 0.9628 - val_loss: 0.2916 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2902 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8832 - val_categorical_output_auc: 0.9496 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2489 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2476 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8952 - categorical_output_auc: 0.9629 - val_loss: 0.2932 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2918 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8818 - val_categorical_output_auc: 0.9492 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2489 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2476 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8956 - categorical_output_auc: 0.9630 - val_loss: 0.2900 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2886 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8843 - val_categorical_output_auc: 0.9503 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2493 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2480 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8953 - categorical_output_auc: 0.9628 - val_loss: 0.2903 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2889 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8841 - val_categorical_output_auc: 0.9502 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2474 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2461 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8953 - categorical_output_auc: 0.9634 - val_loss: 0.2894 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2880 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8840 - val_categorical_output_auc: 0.9505 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2477 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2464 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8960 - categorical_output_auc: 0.9633 - val_loss: 0.2894 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2881 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8849 - val_categorical_output_auc: 0.9504 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2475 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2462 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8958 - categorical_output_auc: 0.9634 - val_loss: 0.2900 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2886 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8832 - val_categorical_output_auc: 0.9503 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2472 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2458 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8963 - categorical_output_auc: 0.9635 - val_loss: 0.2893 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2879 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8839 - val_categorical_output_auc: 0.9506 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2428 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2415 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8985 - categorical_output_auc: 0.9649 - val_loss: 0.2876 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2863 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8850 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2432 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2419 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8981 - categorical_output_auc: 0.9648 - val_loss: 0.2876 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2862 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8855 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2436 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2423 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8977 - categorical_output_auc: 0.9646 - val_loss: 0.2881 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2867 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8853 - val_categorical_output_auc: 0.9510 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2424 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2410 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8987 - categorical_output_auc: 0.9650 - val_loss: 0.2876 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2862 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8856 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2429 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2416 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8982 - categorical_output_auc: 0.9648 - val_loss: 0.2877 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2864 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8858 - val_categorical_output_auc: 0.9511 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2439 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2425 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8979 - categorical_output_auc: 0.9645 - val_loss: 0.2875 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2861 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8853 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2418 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2405 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8985 - categorical_output_auc: 0.9652 - val_loss: 0.2877 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2863 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8849 - val_categorical_output_auc: 0.9511 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2425 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2411 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8986 - categorical_output_auc: 0.9650 - val_loss: 0.2875 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2861 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8855 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2420 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2407 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8986 - categorical_output_auc: 0.9651 - val_loss: 0.2876 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2862 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8854 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2420 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2407 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8984 - categorical_output_auc: 0.9651 - val_loss: 0.2875 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2862 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8853 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-07\n",
      "Epoch 91/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2418 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2404 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8987 - categorical_output_auc: 0.9652 - val_loss: 0.2875 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2861 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8851 - val_categorical_output_auc: 0.9513 - lr: 1.0000e-07\n",
      "Epoch 92/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2424 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2411 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8985 - categorical_output_auc: 0.9650 - val_loss: 0.2876 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2862 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8855 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-07\n",
      "Epoch 93/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2430 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2417 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8974 - categorical_output_auc: 0.9648 - val_loss: 0.2877 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2864 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8854 - val_categorical_output_auc: 0.9511 - lr: 1.0000e-08\n",
      "Epoch 94/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2437 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2424 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8974 - categorical_output_auc: 0.9646 - val_loss: 0.2876 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2862 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8855 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-08\n",
      "Epoch 95/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2428 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2415 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8978 - categorical_output_auc: 0.9648 - val_loss: 0.2870 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2857 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8857 - val_categorical_output_auc: 0.9514 - lr: 1.0000e-08\n",
      "Epoch 96/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2430 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2417 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8982 - categorical_output_auc: 0.9648 - val_loss: 0.2873 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2859 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8852 - val_categorical_output_auc: 0.9513 - lr: 1.0000e-08\n",
      "Epoch 97/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2418 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2405 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8986 - categorical_output_auc: 0.9652 - val_loss: 0.2873 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2859 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8856 - val_categorical_output_auc: 0.9513 - lr: 1.0000e-08\n",
      "Epoch 98/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2426 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2413 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8987 - categorical_output_auc: 0.9649 - val_loss: 0.2872 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2858 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8853 - val_categorical_output_auc: 0.9513 - lr: 1.0000e-08\n",
      "Epoch 99/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2423 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2410 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8984 - categorical_output_auc: 0.9650 - val_loss: 0.2874 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2860 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8854 - val_categorical_output_auc: 0.9512 - lr: 1.0000e-09\n",
      "Epoch 100/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2428 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2414 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8981 - categorical_output_auc: 0.9649 - val_loss: 0.2873 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2859 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8853 - val_categorical_output_auc: 0.9513 - lr: 1.0000e-09\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential([\n",
    "#   layers.Dense(175, activation='relu', input_shape=(233,)),\n",
    "#   layers.BatchNormalization(),\n",
    "#   layers.Dense(175, activation='relu'),\n",
    "#   layers.BatchNormalization(),\n",
    "#   layers.Dense(175, activation='relu'),\n",
    "#   layers.BatchNormalization(),\n",
    "#   layers.Dense(175, activation='relu'),\n",
    "#   layers.BatchNormalization(),\n",
    "#   layers.Dense(175, activation='relu'),\n",
    "#   layers.BatchNormalization(),\n",
    "#   layers.Dense(175, activation='relu'),\n",
    "#   layers.BatchNormalization(),\n",
    "#   layers.Dense(2, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy']) #optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.99)\n",
    "\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, min_delta=0.0001)\n",
    "\n",
    "# model.fit(features, target, epochs=100, batch_size=128, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Define the base of the model using the Sequential API\n",
    "base_model = Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(233,)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),                                                            #\n",
    "    #layers.Dense(32, activation='relu'),\n",
    "])\n",
    "\n",
    "# Create the input layer\n",
    "inputs = Input(shape=(233,))\n",
    "\n",
    "# Get the output from the base model\n",
    "x = base_model(inputs)\n",
    "\n",
    "# Define the two regression outputs\n",
    "regression_output = layers.Dense(1, activation='relu', name='regression_output')(x)\n",
    "\n",
    "\n",
    "# Define the categorical output\n",
    "categorical_output = layers.Dense(2, activation='softmax', name='categorical_output')(x)\n",
    "\n",
    "# Create the Model with one input and three outputs\n",
    "model_SGD = Model(inputs=inputs, outputs=[regression_output, categorical_output])\n",
    "\n",
    "# Compile the model with appropriate loss functions and metrics\n",
    "model_SGD.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),  #0.001 0.9\n",
    "              loss={\n",
    "                  'regression_output': 'mean_squared_error',\n",
    "                  'categorical_output': 'categorical_crossentropy'\n",
    "              },\n",
    "              metrics={\n",
    "                  'regression_output': ['mse'],\n",
    "                  'categorical_output': ['accuracy', 'AUC']\n",
    "              })\n",
    "\n",
    "# Setup for early stopping to monitor the validation loss and stop training when it begins to increase\n",
    "early_stopping = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True, min_delta=0.00001),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.1)\n",
    "    ]\n",
    "\n",
    "# Fit the model (assuming 'features' and 'target' are defined and formatted appropriately for a multi-output model)\n",
    "# This will need to be adjusted based on how your actual target data is structured\n",
    "history_SGD = model_SGD.fit(features_train, {'regression_output': target_reg_train, 'categorical_output': target_cat_train}, \n",
    "          epochs=100, batch_size=128, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e629c43",
   "metadata": {},
   "source": [
    "## Model with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "170d784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1747/1747 [==============================] - 4s 2ms/step - loss: 0.5993 - regression_output_loss: 0.0016 - categorical_output_loss: 0.5977 - regression_output_mse: 0.0016 - categorical_output_accuracy: 0.6753 - categorical_output_auc: 0.7417 - val_loss: 0.5605 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5591 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7040 - val_categorical_output_auc: 0.7821 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.5446 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5432 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7186 - categorical_output_auc: 0.7980 - val_loss: 0.5253 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5240 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7331 - val_categorical_output_auc: 0.8146 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.5089 - regression_output_loss: 0.0013 - categorical_output_loss: 0.5076 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7442 - categorical_output_auc: 0.8286 - val_loss: 0.4932 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4918 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7581 - val_categorical_output_auc: 0.8419 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4783 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4770 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7650 - categorical_output_auc: 0.8513 - val_loss: 0.4638 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4624 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7761 - val_categorical_output_auc: 0.8614 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4563 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4550 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7799 - categorical_output_auc: 0.8667 - val_loss: 0.4496 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4483 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7862 - val_categorical_output_auc: 0.8713 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4359 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4346 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7915 - categorical_output_auc: 0.8793 - val_loss: 0.4308 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4294 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7975 - val_categorical_output_auc: 0.8831 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4199 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4186 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8016 - categorical_output_auc: 0.8890 - val_loss: 0.4127 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4114 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8083 - val_categorical_output_auc: 0.8935 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4061 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4048 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8102 - categorical_output_auc: 0.8967 - val_loss: 0.4100 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4086 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8102 - val_categorical_output_auc: 0.8954 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3933 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3920 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8174 - categorical_output_auc: 0.9035 - val_loss: 0.3974 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3961 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8178 - val_categorical_output_auc: 0.9024 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3840 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3826 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8225 - categorical_output_auc: 0.9084 - val_loss: 0.3923 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3909 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8204 - val_categorical_output_auc: 0.9048 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3733 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3720 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8285 - categorical_output_auc: 0.9136 - val_loss: 0.3827 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3814 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8252 - val_categorical_output_auc: 0.9100 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3646 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3633 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8326 - categorical_output_auc: 0.9179 - val_loss: 0.3774 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3760 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8304 - val_categorical_output_auc: 0.9128 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3571 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3557 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8376 - categorical_output_auc: 0.9214 - val_loss: 0.3725 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3711 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8313 - val_categorical_output_auc: 0.9150 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3497 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3483 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8416 - categorical_output_auc: 0.9248 - val_loss: 0.3637 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3623 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8384 - val_categorical_output_auc: 0.9199 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3441 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3428 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8444 - categorical_output_auc: 0.9273 - val_loss: 0.3609 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3595 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8385 - val_categorical_output_auc: 0.9209 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3362 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3349 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8470 - categorical_output_auc: 0.9305 - val_loss: 0.3542 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3528 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8426 - val_categorical_output_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3322 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3309 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8501 - categorical_output_auc: 0.9324 - val_loss: 0.3511 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3498 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8448 - val_categorical_output_auc: 0.9257 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3258 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3244 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8538 - categorical_output_auc: 0.9351 - val_loss: 0.3446 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3432 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8491 - val_categorical_output_auc: 0.9285 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3219 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3205 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8556 - categorical_output_auc: 0.9368 - val_loss: 0.3451 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3438 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8501 - val_categorical_output_auc: 0.9287 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3162 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3149 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8580 - categorical_output_auc: 0.9388 - val_loss: 0.3390 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3376 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8526 - val_categorical_output_auc: 0.9311 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3124 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3111 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8608 - categorical_output_auc: 0.9404 - val_loss: 0.3378 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3364 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8526 - val_categorical_output_auc: 0.9320 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3089 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3075 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8623 - categorical_output_auc: 0.9418 - val_loss: 0.3345 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3331 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8549 - val_categorical_output_auc: 0.9333 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3041 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3028 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8645 - categorical_output_auc: 0.9435 - val_loss: 0.3276 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3262 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8577 - val_categorical_output_auc: 0.9360 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3000 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2987 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8664 - categorical_output_auc: 0.9452 - val_loss: 0.3285 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3272 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8584 - val_categorical_output_auc: 0.9355 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2967 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2954 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8681 - categorical_output_auc: 0.9464 - val_loss: 0.3277 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3263 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8607 - val_categorical_output_auc: 0.9366 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2963 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2950 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8684 - categorical_output_auc: 0.9466 - val_loss: 0.3246 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3232 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8616 - val_categorical_output_auc: 0.9376 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2909 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2896 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8703 - categorical_output_auc: 0.9484 - val_loss: 0.3218 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3204 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8642 - val_categorical_output_auc: 0.9390 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2880 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2866 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8728 - categorical_output_auc: 0.9496 - val_loss: 0.3211 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3197 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8634 - val_categorical_output_auc: 0.9389 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2848 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2835 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8741 - categorical_output_auc: 0.9507 - val_loss: 0.3135 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3122 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8663 - val_categorical_output_auc: 0.9420 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2828 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2814 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8753 - categorical_output_auc: 0.9514 - val_loss: 0.3156 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3142 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8664 - val_categorical_output_auc: 0.9416 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2797 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2784 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8769 - categorical_output_auc: 0.9526 - val_loss: 0.3154 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3140 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8688 - val_categorical_output_auc: 0.9420 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2777 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2764 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8780 - categorical_output_auc: 0.9532 - val_loss: 0.3108 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3094 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8699 - val_categorical_output_auc: 0.9431 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2757 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2744 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8793 - categorical_output_auc: 0.9539 - val_loss: 0.3176 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3162 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8666 - val_categorical_output_auc: 0.9408 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2728 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2715 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8802 - categorical_output_auc: 0.9549 - val_loss: 0.3148 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3134 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8675 - val_categorical_output_auc: 0.9419 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2711 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2698 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8806 - categorical_output_auc: 0.9554 - val_loss: 0.3073 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3059 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8737 - val_categorical_output_auc: 0.9452 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2665 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2652 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8831 - categorical_output_auc: 0.9569 - val_loss: 0.3062 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3048 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8737 - val_categorical_output_auc: 0.9460 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2662 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2649 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8839 - categorical_output_auc: 0.9571 - val_loss: 0.3053 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3039 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8738 - val_categorical_output_auc: 0.9460 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2641 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2628 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8847 - categorical_output_auc: 0.9578 - val_loss: 0.3029 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3015 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8759 - val_categorical_output_auc: 0.9468 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2622 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2608 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8857 - categorical_output_auc: 0.9584 - val_loss: 0.3044 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3030 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8757 - val_categorical_output_auc: 0.9468 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2611 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2598 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8864 - categorical_output_auc: 0.9587 - val_loss: 0.3071 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3057 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8740 - val_categorical_output_auc: 0.9453 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2595 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2582 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8863 - categorical_output_auc: 0.9592 - val_loss: 0.3007 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2994 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8774 - val_categorical_output_auc: 0.9480 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2573 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2560 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8872 - categorical_output_auc: 0.9599 - val_loss: 0.3006 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2992 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8756 - val_categorical_output_auc: 0.9480 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2555 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2542 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8880 - categorical_output_auc: 0.9605 - val_loss: 0.2974 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2961 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8789 - val_categorical_output_auc: 0.9491 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2530 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2516 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8908 - categorical_output_auc: 0.9613 - val_loss: 0.2975 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2961 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8794 - val_categorical_output_auc: 0.9494 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2520 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2507 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8903 - categorical_output_auc: 0.9616 - val_loss: 0.2967 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2953 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8772 - val_categorical_output_auc: 0.9493 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2509 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2496 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8909 - categorical_output_auc: 0.9619 - val_loss: 0.3000 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2986 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8773 - val_categorical_output_auc: 0.9479 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2481 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2468 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8921 - categorical_output_auc: 0.9628 - val_loss: 0.3021 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3007 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8786 - val_categorical_output_auc: 0.9488 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2479 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2465 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8930 - categorical_output_auc: 0.9628 - val_loss: 0.2940 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2926 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8821 - val_categorical_output_auc: 0.9511 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2458 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2445 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8937 - categorical_output_auc: 0.9634 - val_loss: 0.2940 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2926 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8838 - val_categorical_output_auc: 0.9512 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2449 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2436 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8939 - categorical_output_auc: 0.9637 - val_loss: 0.2946 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2932 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8816 - val_categorical_output_auc: 0.9506 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2418 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2404 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8957 - categorical_output_auc: 0.9647 - val_loss: 0.2989 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2975 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8815 - val_categorical_output_auc: 0.9496 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2092 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2078 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9104 - categorical_output_auc: 0.9737 - val_loss: 0.2704 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2691 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8973 - val_categorical_output_auc: 0.9596 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1971 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1958 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9162 - categorical_output_auc: 0.9766 - val_loss: 0.2677 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2663 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9015 - val_categorical_output_auc: 0.9609 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1925 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1912 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9177 - categorical_output_auc: 0.9777 - val_loss: 0.2665 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2651 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9020 - val_categorical_output_auc: 0.9616 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1879 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1866 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9206 - categorical_output_auc: 0.9787 - val_loss: 0.2666 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2653 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9031 - val_categorical_output_auc: 0.9621 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1865 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1852 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9210 - categorical_output_auc: 0.9790 - val_loss: 0.2654 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2640 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9040 - val_categorical_output_auc: 0.9625 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1841 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1827 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9219 - categorical_output_auc: 0.9796 - val_loss: 0.2654 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2640 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9049 - val_categorical_output_auc: 0.9628 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1835 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1822 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9219 - categorical_output_auc: 0.9796 - val_loss: 0.2685 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2671 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9047 - val_categorical_output_auc: 0.9626 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1822 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1809 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9226 - categorical_output_auc: 0.9800 - val_loss: 0.2689 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2675 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9053 - val_categorical_output_auc: 0.9625 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1776 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1762 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9250 - categorical_output_auc: 0.9810 - val_loss: 0.2676 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2662 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9059 - val_categorical_output_auc: 0.9629 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1780 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1767 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9245 - categorical_output_auc: 0.9809 - val_loss: 0.2675 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2661 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9061 - val_categorical_output_auc: 0.9630 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1759 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1746 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9257 - categorical_output_auc: 0.9814 - val_loss: 0.2667 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2653 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9064 - val_categorical_output_auc: 0.9633 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1767 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1754 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9254 - categorical_output_auc: 0.9812 - val_loss: 0.2669 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2655 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9063 - val_categorical_output_auc: 0.9632 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "#Most code is unnecessary here but is kept to not introduce any mistakes\n",
    "\n",
    "\n",
    "\n",
    "base_model = Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(233,)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),                                                            #\n",
    "    #layers.Dense(32, activation='relu'),\n",
    "])\n",
    "\n",
    "# Create the input layer\n",
    "inputs = Input(shape=(233,))\n",
    "\n",
    "# Get the output from the base model\n",
    "x = base_model(inputs)\n",
    "\n",
    "# Define the two regression outputs\n",
    "regression_output = layers.Dense(1, activation='relu', name='regression_output')(x)\n",
    "\n",
    "\n",
    "# Define the categorical output\n",
    "categorical_output = layers.Dense(2, activation='softmax', name='categorical_output')(x)\n",
    "\n",
    "# Create the Model with one input and three outputs\n",
    "model_adam = Model(inputs=inputs, outputs=[regression_output, categorical_output])\n",
    "\n",
    "# Compile the model with appropriate loss functions and metrics\n",
    "model_adam.compile('adam',  #0.001 0.9\n",
    "              loss={\n",
    "                  'regression_output': 'mean_squared_error',\n",
    "                  'categorical_output': 'categorical_crossentropy'\n",
    "              },\n",
    "              metrics={\n",
    "                  'regression_output': ['mse'],\n",
    "                  'categorical_output': ['accuracy', 'AUC']\n",
    "              })\n",
    "\n",
    "# Setup for early stopping to monitor the validation loss and stop training when it begins to increase\n",
    "early_stopping = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True, min_delta=0.00001),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.1)\n",
    "    ]\n",
    "\n",
    "# Fit the model (assuming 'features' and 'target' are defined and formatted appropriately for a multi-output model)\n",
    "# This will need to be adjusted based on how your actual target data is structured\n",
    "history_adam = model_adam.fit(features_train, {'regression_output': target_reg_train, 'categorical_output': target_cat_train}, \n",
    "          epochs=100, batch_size=128, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169a6bb",
   "metadata": {},
   "source": [
    "## Model with constant BatchNormailzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76ff342f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1747/1747 [==============================] - 10s 5ms/step - loss: 0.6132 - regression_output_loss: 0.0060 - categorical_output_loss: 0.6073 - regression_output_mse: 0.0060 - categorical_output_accuracy: 0.6679 - categorical_output_auc: 0.7317 - val_loss: 0.5654 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5640 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7013 - val_categorical_output_auc: 0.7786 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.5503 - regression_output_loss: 0.0015 - categorical_output_loss: 0.5487 - regression_output_mse: 0.0015 - categorical_output_accuracy: 0.7165 - categorical_output_auc: 0.7935 - val_loss: 0.5253 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.5239 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7361 - val_categorical_output_auc: 0.8154 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.5038 - regression_output_loss: 0.0014 - categorical_output_loss: 0.5024 - regression_output_mse: 0.0014 - categorical_output_accuracy: 0.7525 - categorical_output_auc: 0.8336 - val_loss: 0.4839 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4825 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7662 - val_categorical_output_auc: 0.8481 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.4616 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4602 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.7808 - categorical_output_auc: 0.8639 - val_loss: 0.4550 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4536 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.7843 - val_categorical_output_auc: 0.8676 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.4253 - regression_output_loss: 0.0013 - categorical_output_loss: 0.4239 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8037 - categorical_output_auc: 0.8864 - val_loss: 0.4264 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.4250 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8004 - val_categorical_output_auc: 0.8860 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.3953 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3940 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8205 - categorical_output_auc: 0.9030 - val_loss: 0.3953 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3939 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8192 - val_categorical_output_auc: 0.9027 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.3684 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3671 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8358 - categorical_output_auc: 0.9163 - val_loss: 0.3757 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3743 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8325 - val_categorical_output_auc: 0.9130 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.3492 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3479 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8455 - categorical_output_auc: 0.9253 - val_loss: 0.3629 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3615 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8399 - val_categorical_output_auc: 0.9193 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.3309 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3296 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8555 - categorical_output_auc: 0.9332 - val_loss: 0.3467 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3453 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8475 - val_categorical_output_auc: 0.9264 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.3165 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3152 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8625 - categorical_output_auc: 0.9391 - val_loss: 0.3463 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3449 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8482 - val_categorical_output_auc: 0.9271 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.3015 - regression_output_loss: 0.0013 - categorical_output_loss: 0.3002 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8697 - categorical_output_auc: 0.9448 - val_loss: 0.3279 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3265 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8596 - val_categorical_output_auc: 0.9355 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.2891 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2878 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8757 - categorical_output_auc: 0.9494 - val_loss: 0.3197 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3183 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8636 - val_categorical_output_auc: 0.9388 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.2807 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2794 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8809 - categorical_output_auc: 0.9523 - val_loss: 0.3139 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3125 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8673 - val_categorical_output_auc: 0.9407 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.2705 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2691 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8856 - categorical_output_auc: 0.9557 - val_loss: 0.3061 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.3047 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8721 - val_categorical_output_auc: 0.9443 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.2612 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2599 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8900 - categorical_output_auc: 0.9588 - val_loss: 0.3000 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2986 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8754 - val_categorical_output_auc: 0.9465 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.2546 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2532 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8923 - categorical_output_auc: 0.9609 - val_loss: 0.2875 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2861 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8826 - val_categorical_output_auc: 0.9507 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.2462 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2449 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8968 - categorical_output_auc: 0.9634 - val_loss: 0.2884 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2871 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8833 - val_categorical_output_auc: 0.9510 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.2404 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2390 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9007 - categorical_output_auc: 0.9651 - val_loss: 0.2850 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2836 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8857 - val_categorical_output_auc: 0.9529 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.2338 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2325 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9025 - categorical_output_auc: 0.9670 - val_loss: 0.2818 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2805 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8869 - val_categorical_output_auc: 0.9539 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.2278 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2264 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9050 - categorical_output_auc: 0.9687 - val_loss: 0.2756 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2742 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8889 - val_categorical_output_auc: 0.9550 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.2224 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2211 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9083 - categorical_output_auc: 0.9701 - val_loss: 0.2746 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2733 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8926 - val_categorical_output_auc: 0.9568 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "1747/1747 [==============================] - 9s 5ms/step - loss: 0.2174 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2161 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9108 - categorical_output_auc: 0.9715 - val_loss: 0.2810 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2797 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8886 - val_categorical_output_auc: 0.9545 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.2129 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2116 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9123 - categorical_output_auc: 0.9727 - val_loss: 0.2673 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2659 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8966 - val_categorical_output_auc: 0.9591 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "1747/1747 [==============================] - 8s 4ms/step - loss: 0.2072 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2059 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9143 - categorical_output_auc: 0.9741 - val_loss: 0.2671 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2657 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8976 - val_categorical_output_auc: 0.9591 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.2033 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2020 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9175 - categorical_output_auc: 0.9750 - val_loss: 0.2598 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2584 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9006 - val_categorical_output_auc: 0.9611 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1989 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1976 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9185 - categorical_output_auc: 0.9761 - val_loss: 0.2739 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2725 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.8970 - val_categorical_output_auc: 0.9587 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1949 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1936 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9208 - categorical_output_auc: 0.9770 - val_loss: 0.2575 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2562 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9034 - val_categorical_output_auc: 0.9622 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1914 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1901 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9223 - categorical_output_auc: 0.9778 - val_loss: 0.2621 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2608 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9039 - val_categorical_output_auc: 0.9624 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1889 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1876 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9236 - categorical_output_auc: 0.9784 - val_loss: 0.2645 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2631 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9023 - val_categorical_output_auc: 0.9613 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1832 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1818 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9256 - categorical_output_auc: 0.9797 - val_loss: 0.2731 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2717 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9035 - val_categorical_output_auc: 0.9611 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1431 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1418 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9430 - categorical_output_auc: 0.9876 - val_loss: 0.2447 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2434 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9195 - val_categorical_output_auc: 0.9694 - lr: 1.0000e-04\n",
      "Epoch 32/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1248 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1234 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9512 - categorical_output_auc: 0.9904 - val_loss: 0.2436 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2422 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9233 - val_categorical_output_auc: 0.9707 - lr: 1.0000e-04\n",
      "Epoch 33/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1183 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1170 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9538 - categorical_output_auc: 0.9914 - val_loss: 0.2419 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2405 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9261 - val_categorical_output_auc: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 34/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1137 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1124 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9550 - categorical_output_auc: 0.9921 - val_loss: 0.2456 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2442 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9279 - val_categorical_output_auc: 0.9713 - lr: 1.0000e-04\n",
      "Epoch 35/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1101 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1088 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9564 - categorical_output_auc: 0.9926 - val_loss: 0.2439 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2425 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9289 - val_categorical_output_auc: 0.9720 - lr: 1.0000e-04\n",
      "Epoch 36/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1076 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1063 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9571 - categorical_output_auc: 0.9929 - val_loss: 0.2465 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2451 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9301 - val_categorical_output_auc: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 37/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.1016 - regression_output_loss: 0.0013 - categorical_output_loss: 0.1003 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9597 - categorical_output_auc: 0.9937 - val_loss: 0.2505 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2491 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9298 - val_categorical_output_auc: 0.9715 - lr: 1.0000e-05\n",
      "Epoch 38/150\n",
      "1747/1747 [==============================] - 8s 4ms/step - loss: 0.1003 - regression_output_loss: 0.0013 - categorical_output_loss: 0.0990 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9605 - categorical_output_auc: 0.9939 - val_loss: 0.2498 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2484 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9307 - val_categorical_output_auc: 0.9718 - lr: 1.0000e-05\n",
      "Epoch 39/150\n",
      "1747/1747 [==============================] - 8s 5ms/step - loss: 0.0990 - regression_output_loss: 0.0013 - categorical_output_loss: 0.0977 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9608 - categorical_output_auc: 0.9940 - val_loss: 0.2523 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2509 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9305 - val_categorical_output_auc: 0.9717 - lr: 1.0000e-05\n",
      "Epoch 40/150\n",
      "1747/1747 [==============================] - 8s 4ms/step - loss: 0.0985 - regression_output_loss: 0.0013 - categorical_output_loss: 0.0972 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9611 - categorical_output_auc: 0.9940 - val_loss: 0.2531 - val_regression_output_loss: 0.0014 - val_categorical_output_loss: 0.2518 - val_regression_output_mse: 0.0014 - val_categorical_output_accuracy: 0.9303 - val_categorical_output_auc: 0.9717 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "#Most code is unnecessary here but is kept to not introduce any mistakes\n",
    "\n",
    "\n",
    "\n",
    "base_model = Sequential([\n",
    "    layers.Dense(800, activation='relu', input_shape=(233,)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(400, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(150, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),                                                          #\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "])\n",
    "\n",
    "# Create the input layer\n",
    "inputs = Input(shape=(233,))\n",
    "\n",
    "# Get the output from the base model\n",
    "x = base_model(inputs)\n",
    "\n",
    "# Define the two regression outputs\n",
    "regression_output = layers.Dense(1, activation='relu', name='regression_output')(x)\n",
    "\n",
    "\n",
    "# Define the categorical output\n",
    "categorical_output = layers.Dense(2, activation='softmax', name='categorical_output')(x)\n",
    "\n",
    "# Create the Model with one input and three outputs\n",
    "model_batch = Model(inputs=inputs, outputs=[regression_output, categorical_output])\n",
    "\n",
    "# Compile the model with appropriate loss functions and metrics\n",
    "model_batch.compile('adam',  #0.001 0.9\n",
    "              loss={\n",
    "                  'regression_output': 'mean_squared_error',\n",
    "                  'categorical_output': 'categorical_crossentropy'\n",
    "              },\n",
    "              metrics={\n",
    "                  'regression_output': ['mse'],\n",
    "                  'categorical_output': ['accuracy', 'AUC']\n",
    "              })\n",
    "\n",
    "# Setup for early stopping to monitor the validation loss and stop training when it begins to increase\n",
    "early_stopping = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True, min_delta=0.00001),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.1)\n",
    "    ]\n",
    "\n",
    "# Fit the model (assuming 'features' and 'target' are defined and formatted appropriately for a multi-output model)\n",
    "# This will need to be adjusted based on how your actual target data is structured\n",
    "history_batch = model_batch.fit(features_train, {'regression_output': target_reg_train, 'categorical_output': target_cat_train}, \n",
    "          epochs=150, batch_size=128, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd86c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12275e",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f377b25",
   "metadata": {},
   "source": [
    "To compare the models with each other we use the test dataset to compare predictions with targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31c84f",
   "metadata": {},
   "source": [
    "## Evaluation Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3871c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2184/2184 [==============================] - 1s 502us/step - loss: 0.2848 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2835 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.8873 - categorical_output_auc: 0.9521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28475674986839294,\n",
       " 0.0012976734433323145,\n",
       " 0.2834596633911133,\n",
       " 0.0012976734433323145,\n",
       " 0.8872525691986084,\n",
       " 0.9520988464355469]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SGD.evaluate(features_test, [target_reg_test, target_cat_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72949248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2184/2184 [==============================] - 1s 506us/step - loss: 0.2556 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2543 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9059 - categorical_output_auc: 0.9645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2555706799030304,\n",
       " 0.0012976734433323145,\n",
       " 0.25427311658859253,\n",
       " 0.0012976734433323145,\n",
       " 0.905872106552124,\n",
       " 0.9644667506217957]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adam.evaluate(features_test, [target_reg_test, target_cat_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d902aa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2184/2184 [==============================] - 2s 790us/step - loss: 0.2352 - regression_output_loss: 0.0013 - categorical_output_loss: 0.2340 - regression_output_mse: 0.0013 - categorical_output_accuracy: 0.9282 - categorical_output_auc: 0.9723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23524868488311768,\n",
       " 0.0012976734433323145,\n",
       " 0.23395104706287384,\n",
       " 0.0012976734433323145,\n",
       " 0.9281696677207947,\n",
       " 0.9722997546195984]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_batch.evaluate(features_test, [target_reg_test, target_cat_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e21499",
   "metadata": {},
   "source": [
    "The adam optimizer show clearly better results, that is why it was choosen for the final model \"model_batch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf67c1a4",
   "metadata": {},
   "source": [
    "## Evaluation Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca792e8",
   "metadata": {},
   "source": [
    "Here we further test our model on the holdout data, which is not upsampled, to test out of batch performance of our final model. Also the other models are tested out of curiosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22c40ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 538us/step - loss: 0.4222 - regression_output_loss: 5.4869e-04 - categorical_output_loss: 0.4216 - regression_output_mse: 5.4869e-04 - categorical_output_accuracy: 0.8250 - categorical_output_auc: 0.9096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4221813976764679,\n",
       " 0.000548690790310502,\n",
       " 0.42163264751434326,\n",
       " 0.000548690790310502,\n",
       " 0.8250459432601929,\n",
       " 0.9095830917358398]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SGD.evaluate(features_holdout, [target_reg_holdout, target_cat_holdout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d20f5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 519us/step - loss: 0.4574 - regression_output_loss: 5.4869e-04 - categorical_output_loss: 0.4569 - regression_output_mse: 5.4869e-04 - categorical_output_accuracy: 0.8376 - categorical_output_auc: 0.9268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4574055075645447,\n",
       " 0.000548690790310502,\n",
       " 0.4568568766117096,\n",
       " 0.000548690790310502,\n",
       " 0.83758145570755,\n",
       " 0.9268087148666382]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adam.evaluate(features_holdout, [target_reg_holdout, target_cat_holdout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c52309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 1s 798us/step - loss: 0.4725 - regression_output_loss: 5.4869e-04 - categorical_output_loss: 0.4719 - regression_output_mse: 5.4869e-04 - categorical_output_accuracy: 0.8676 - categorical_output_auc: 0.9383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4724702537059784,\n",
       " 0.000548690790310502,\n",
       " 0.4719213843345642,\n",
       " 0.000548690790310502,\n",
       " 0.8676249384880066,\n",
       " 0.9382568001747131]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_batch.evaluate(features_holdout, [target_reg_holdout, target_cat_holdout])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a13e261",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9c378",
   "metadata": {},
   "source": [
    "To further illustrate the perfomance of our model, we created a ROC plot. This also compares the first model to the last model. No plot for the accuracy of teh regression output was made because there was no improvement throughout the models. The mse stayed the same model to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e4a9b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 419us/step\n",
      "748/748 [==============================] - 1s 694us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict probabilities for the categorical output\n",
    "y_pred_prob_SGD = model_SGD.predict(features_holdout)[1]  # Assuming the second output is the categorical one\n",
    "y_pred_prob_batch = model_batch.predict(features_holdout)[1]\n",
    "\n",
    "# Extract the probabilities for the positive class (index 1)\n",
    "y_pred_prob_pos_SGD= y_pred_prob_SGD[:, 1]\n",
    "y_pred_prob_pos_batch = y_pred_prob_batch[:, 1]\n",
    "\n",
    "# Compute the ROC curve and AUC score for the positive class\n",
    "fpr_SGD, tpr_SGD, _ = roc_curve(target_cat_holdout[:, 1], y_pred_prob_pos_SGD)\n",
    "roc_auc_SGD = auc(fpr_SGD,tpr_SGD)\n",
    "\n",
    "fpr_batch, tpr_batch, _ = roc_curve(target_cat_holdout[:, 1], y_pred_prob_pos_batch)\n",
    "roc_auc_batch = auc(fpr_batch,tpr_batch)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_SGD, tpr_SGD, label=f'ROC curve SGD(area = 0.9062)')\n",
    "plt.plot(fpr_batch, tpr_batch, label=f'ROC curve BatchNormalization & ADAM (area = 0.9378)')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "plt.savefig('roc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9faea8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f412b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea09f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7172e0f",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "891235d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a model\n",
    "#model_adam.save('model_out_adam.h5')\n",
    "#model_SGD.save('model_out_SGD.h5')\n",
    "model_batch.save('model_out_batch.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b7038-f84a-49b7-9239-0f55aea31399",
   "metadata": {},
   "source": [
    "Test dataset results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5d0eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('~/Documents/My Docs/Advance Topics in PA/APA Project FIiles/proc_data_test_students.csv',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8eb1122e-51bc-450c-b2b3-47ad3dad764a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_time</th>\n",
       "      <th>final_time</th>\n",
       "      <th>section</th>\n",
       "      <th>cavity</th>\n",
       "      <th>gobdiameteraverage_avg</th>\n",
       "      <th>gobdiameteraverage_min</th>\n",
       "      <th>gobdiameteraverage_max</th>\n",
       "      <th>gobdiameteraverage_std</th>\n",
       "      <th>goblengthaverage_avg</th>\n",
       "      <th>goblengthaverage_min</th>\n",
       "      <th>...</th>\n",
       "      <th>production</th>\n",
       "      <th>center_top_tc_avg</th>\n",
       "      <th>center_top_tc_min</th>\n",
       "      <th>center_top_tc_max</th>\n",
       "      <th>center_top_tc_std</th>\n",
       "      <th>feeder_global_avg</th>\n",
       "      <th>feeder_global_min</th>\n",
       "      <th>feeder_global_max</th>\n",
       "      <th>feeder_global_diff_min_max</th>\n",
       "      <th>feeder_global_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/08/2023 23:20</td>\n",
       "      <td>01/09/2023 00:40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>215.694660</td>\n",
       "      <td>255.892133</td>\n",
       "      <td>74.105771</td>\n",
       "      <td>9.464855</td>\n",
       "      <td>1051.704749</td>\n",
       "      <td>3035.874078</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.392081</td>\n",
       "      <td>6816.379009</td>\n",
       "      <td>3172.312657</td>\n",
       "      <td>0.444773</td>\n",
       "      <td>3428.784340</td>\n",
       "      <td>9860.097470</td>\n",
       "      <td>6904.340651</td>\n",
       "      <td>161.952193</td>\n",
       "      <td>1.105749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31/08/2023 23:40</td>\n",
       "      <td>01/09/2023 01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>215.979741</td>\n",
       "      <td>256.893302</td>\n",
       "      <td>74.105771</td>\n",
       "      <td>13.173013</td>\n",
       "      <td>1055.352268</td>\n",
       "      <td>3064.549153</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.333417</td>\n",
       "      <td>6816.379009</td>\n",
       "      <td>3172.312657</td>\n",
       "      <td>0.472326</td>\n",
       "      <td>3428.780572</td>\n",
       "      <td>9860.097470</td>\n",
       "      <td>6903.758213</td>\n",
       "      <td>161.324715</td>\n",
       "      <td>1.108167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/09/2023 00:00</td>\n",
       "      <td>01/09/2023 01:20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>217.296343</td>\n",
       "      <td>256.893302</td>\n",
       "      <td>75.456263</td>\n",
       "      <td>9.465147</td>\n",
       "      <td>1049.671530</td>\n",
       "      <td>3018.143689</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.585489</td>\n",
       "      <td>6816.379009</td>\n",
       "      <td>3172.557688</td>\n",
       "      <td>0.551891</td>\n",
       "      <td>3428.901827</td>\n",
       "      <td>9860.607646</td>\n",
       "      <td>6903.758213</td>\n",
       "      <td>160.948228</td>\n",
       "      <td>1.215840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/09/2023 00:20</td>\n",
       "      <td>01/09/2023 01:40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>217.947856</td>\n",
       "      <td>256.893302</td>\n",
       "      <td>75.456263</td>\n",
       "      <td>12.930391</td>\n",
       "      <td>1046.292321</td>\n",
       "      <td>3018.143689</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.925557</td>\n",
       "      <td>6816.671647</td>\n",
       "      <td>3172.557688</td>\n",
       "      <td>0.525634</td>\n",
       "      <td>3429.055589</td>\n",
       "      <td>9862.733382</td>\n",
       "      <td>6903.758213</td>\n",
       "      <td>159.379532</td>\n",
       "      <td>1.156055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/09/2023 00:40</td>\n",
       "      <td>01/09/2023 02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>219.256815</td>\n",
       "      <td>260.007334</td>\n",
       "      <td>75.456263</td>\n",
       "      <td>12.046937</td>\n",
       "      <td>1048.182278</td>\n",
       "      <td>3018.143689</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.821062</td>\n",
       "      <td>6816.671647</td>\n",
       "      <td>3172.557688</td>\n",
       "      <td>0.544653</td>\n",
       "      <td>3429.039656</td>\n",
       "      <td>9863.158529</td>\n",
       "      <td>6903.758213</td>\n",
       "      <td>159.065792</td>\n",
       "      <td>0.712606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01/09/2023 01:00</td>\n",
       "      <td>01/09/2023 02:20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>218.611838</td>\n",
       "      <td>258.505939</td>\n",
       "      <td>75.456263</td>\n",
       "      <td>8.859397</td>\n",
       "      <td>1046.058448</td>\n",
       "      <td>3018.143689</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.749565</td>\n",
       "      <td>6816.905759</td>\n",
       "      <td>3172.557688</td>\n",
       "      <td>0.537467</td>\n",
       "      <td>3429.053805</td>\n",
       "      <td>9863.583676</td>\n",
       "      <td>6903.758213</td>\n",
       "      <td>158.752053</td>\n",
       "      <td>0.674876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01/09/2023 01:20</td>\n",
       "      <td>01/09/2023 02:40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>217.952984</td>\n",
       "      <td>258.505939</td>\n",
       "      <td>74.994645</td>\n",
       "      <td>12.521846</td>\n",
       "      <td>1049.932646</td>\n",
       "      <td>3028.319576</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.579990</td>\n",
       "      <td>6816.613120</td>\n",
       "      <td>3172.666591</td>\n",
       "      <td>0.574401</td>\n",
       "      <td>3429.006987</td>\n",
       "      <td>9863.583676</td>\n",
       "      <td>6903.699969</td>\n",
       "      <td>158.689305</td>\n",
       "      <td>0.699650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01/09/2023 01:40</td>\n",
       "      <td>01/09/2023 03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>219.853926</td>\n",
       "      <td>258.505939</td>\n",
       "      <td>76.734718</td>\n",
       "      <td>9.319123</td>\n",
       "      <td>1047.750043</td>\n",
       "      <td>3028.319576</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.532325</td>\n",
       "      <td>6816.613120</td>\n",
       "      <td>3172.666591</td>\n",
       "      <td>0.538612</td>\n",
       "      <td>3428.983779</td>\n",
       "      <td>9863.583676</td>\n",
       "      <td>6903.699969</td>\n",
       "      <td>158.689305</td>\n",
       "      <td>0.616875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01/09/2023 02:00</td>\n",
       "      <td>01/09/2023 03:20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220.488847</td>\n",
       "      <td>258.505939</td>\n",
       "      <td>76.734718</td>\n",
       "      <td>12.729786</td>\n",
       "      <td>1042.597813</td>\n",
       "      <td>3028.319576</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.853144</td>\n",
       "      <td>6816.613120</td>\n",
       "      <td>3172.857171</td>\n",
       "      <td>0.582254</td>\n",
       "      <td>3429.062824</td>\n",
       "      <td>9864.519000</td>\n",
       "      <td>6904.573626</td>\n",
       "      <td>158.940297</td>\n",
       "      <td>0.696434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01/09/2023 02:20</td>\n",
       "      <td>01/09/2023 03:40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>223.892925</td>\n",
       "      <td>266.040188</td>\n",
       "      <td>76.897423</td>\n",
       "      <td>10.095118</td>\n",
       "      <td>1038.573160</td>\n",
       "      <td>3004.921975</td>\n",
       "      <td>...</td>\n",
       "      <td>2796B123UVA_23/08/2023</td>\n",
       "      <td>8649.942973</td>\n",
       "      <td>6816.613120</td>\n",
       "      <td>3172.857171</td>\n",
       "      <td>0.545204</td>\n",
       "      <td>3429.046871</td>\n",
       "      <td>9864.008823</td>\n",
       "      <td>6904.573626</td>\n",
       "      <td>159.316784</td>\n",
       "      <td>0.704763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       initial_time        final_time  section  cavity  \\\n",
       "0  31/08/2023 23:20  01/09/2023 00:40        1       2   \n",
       "1  31/08/2023 23:40  01/09/2023 01:00        1       2   \n",
       "2  01/09/2023 00:00  01/09/2023 01:20        1       2   \n",
       "3  01/09/2023 00:20  01/09/2023 01:40        1       2   \n",
       "4  01/09/2023 00:40  01/09/2023 02:00        1       2   \n",
       "5  01/09/2023 01:00  01/09/2023 02:20        1       2   \n",
       "6  01/09/2023 01:20  01/09/2023 02:40        1       2   \n",
       "7  01/09/2023 01:40  01/09/2023 03:00        1       2   \n",
       "8  01/09/2023 02:00  01/09/2023 03:20        1       2   \n",
       "9  01/09/2023 02:20  01/09/2023 03:40        1       2   \n",
       "\n",
       "   gobdiameteraverage_avg  gobdiameteraverage_min  gobdiameteraverage_max  \\\n",
       "0              215.694660              255.892133               74.105771   \n",
       "1              215.979741              256.893302               74.105771   \n",
       "2              217.296343              256.893302               75.456263   \n",
       "3              217.947856              256.893302               75.456263   \n",
       "4              219.256815              260.007334               75.456263   \n",
       "5              218.611838              258.505939               75.456263   \n",
       "6              217.952984              258.505939               74.994645   \n",
       "7              219.853926              258.505939               76.734718   \n",
       "8              220.488847              258.505939               76.734718   \n",
       "9              223.892925              266.040188               76.897423   \n",
       "\n",
       "   gobdiameteraverage_std  goblengthaverage_avg  goblengthaverage_min  ...  \\\n",
       "0                9.464855           1051.704749           3035.874078  ...   \n",
       "1               13.173013           1055.352268           3064.549153  ...   \n",
       "2                9.465147           1049.671530           3018.143689  ...   \n",
       "3               12.930391           1046.292321           3018.143689  ...   \n",
       "4               12.046937           1048.182278           3018.143689  ...   \n",
       "5                8.859397           1046.058448           3018.143689  ...   \n",
       "6               12.521846           1049.932646           3028.319576  ...   \n",
       "7                9.319123           1047.750043           3028.319576  ...   \n",
       "8               12.729786           1042.597813           3028.319576  ...   \n",
       "9               10.095118           1038.573160           3004.921975  ...   \n",
       "\n",
       "               production  center_top_tc_avg  center_top_tc_min  \\\n",
       "0  2796B123UVA_23/08/2023        8649.392081        6816.379009   \n",
       "1  2796B123UVA_23/08/2023        8649.333417        6816.379009   \n",
       "2  2796B123UVA_23/08/2023        8649.585489        6816.379009   \n",
       "3  2796B123UVA_23/08/2023        8649.925557        6816.671647   \n",
       "4  2796B123UVA_23/08/2023        8649.821062        6816.671647   \n",
       "5  2796B123UVA_23/08/2023        8649.749565        6816.905759   \n",
       "6  2796B123UVA_23/08/2023        8649.579990        6816.613120   \n",
       "7  2796B123UVA_23/08/2023        8649.532325        6816.613120   \n",
       "8  2796B123UVA_23/08/2023        8649.853144        6816.613120   \n",
       "9  2796B123UVA_23/08/2023        8649.942973        6816.613120   \n",
       "\n",
       "   center_top_tc_max  center_top_tc_std  feeder_global_avg  feeder_global_min  \\\n",
       "0        3172.312657           0.444773        3428.784340        9860.097470   \n",
       "1        3172.312657           0.472326        3428.780572        9860.097470   \n",
       "2        3172.557688           0.551891        3428.901827        9860.607646   \n",
       "3        3172.557688           0.525634        3429.055589        9862.733382   \n",
       "4        3172.557688           0.544653        3429.039656        9863.158529   \n",
       "5        3172.557688           0.537467        3429.053805        9863.583676   \n",
       "6        3172.666591           0.574401        3429.006987        9863.583676   \n",
       "7        3172.666591           0.538612        3428.983779        9863.583676   \n",
       "8        3172.857171           0.582254        3429.062824        9864.519000   \n",
       "9        3172.857171           0.545204        3429.046871        9864.008823   \n",
       "\n",
       "   feeder_global_max  feeder_global_diff_min_max  feeder_global_std  \n",
       "0        6904.340651                  161.952193           1.105749  \n",
       "1        6903.758213                  161.324715           1.108167  \n",
       "2        6903.758213                  160.948228           1.215840  \n",
       "3        6903.758213                  159.379532           1.156055  \n",
       "4        6903.758213                  159.065792           0.712606  \n",
       "5        6903.758213                  158.752053           0.674876  \n",
       "6        6903.699969                  158.689305           0.699650  \n",
       "7        6903.699969                  158.689305           0.616875  \n",
       "8        6904.573626                  158.940297           0.696434  \n",
       "9        6904.573626                  159.316784           0.704763  \n",
       "\n",
       "[10 rows x 236 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3dc3b79-03d9-43da-936e-39873cac8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44161, 233)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Handle Timestamps in features dataset\n",
    "# Convert initial_time and final_time to datetime, and create a new feature 'duration'\n",
    "test_data['initial_time'] = pd.to_datetime(test_data['initial_time'], dayfirst=True)\n",
    "test_data['final_time'] = pd.to_datetime(test_data['final_time'], dayfirst=True)\n",
    "test_data['duration'] = (test_data['final_time'] - test_data['initial_time']).dt.total_seconds() / 60.0  # duration in minutes\n",
    "\n",
    "# Drop not needed features\n",
    "test_data = test_data.drop(['initial_time', 'final_time', 'reference', 'production'], axis=1)\n",
    "\n",
    "# Apply StandardScaler to the test data\n",
    "scaler = StandardScaler()\n",
    "test_data = scaler.fit_transform(test_data)\n",
    "\n",
    "# Check the shape of the processed test_data\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db628e-31f0-4d0e-a32b-34c28a32f6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ba160-a722-456c-ab99-47dfb4447dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and outcome \n",
    "features_test = holdout_data.iloc[:, :-2]  # All rows, all columns except the last one\n",
    "target_reg_holdout = holdout_data.iloc[:, -2] \n",
    "target_cat_holdout = holdout_data.iloc[:, -1] \n",
    "\n",
    "#convert target to categorical\n",
    "#target1r =\n",
    "#target2r =\n",
    "target_cat_holdout = to_categorical(target_cat_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a977cf51-6020-4d51-ada4-957d39af0dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1381/1381 [==============================] - 1s 847us/step\n",
      "Output saved to output/predictions_output.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming model_API is your trained model and scaled_test_data is the preprocessed test data\n",
    "\n",
    "# Make predictions\n",
    "predictions = model_batch.predict(test_data)\n",
    "\n",
    "# Separate predictions for regression and classification outputs\n",
    "predictions_reg = predictions[0]  # Regression output (perc_defects_Sidewall)\n",
    "predictions_class = predictions[1]  # Classification output (has_deffect probabilities)\n",
    "\n",
    "# Create a DataFrame with the desired columns\n",
    "output_df = pd.DataFrame({\n",
    "    'perc_defects_Sidewall': predictions_reg.flatten(),  # Assuming regression output is already the required value\n",
    "    'has_deffect': predictions_class[:, 1]  # Probability of defect\n",
    "})\n",
    "\n",
    "# Convert DataFrame to a string with columns separated by \";\"\n",
    "output_str = output_df.to_csv(index=False, sep=';')\n",
    "\n",
    "# Define the directory and filename\n",
    "output_dir = 'output'\n",
    "output_filename = 'predictions_output.csv'\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the file to the specified path\n",
    "with open(output_path, 'w') as file:\n",
    "    file.write(output_str)\n",
    "\n",
    "print(f\"Output saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8b64528-f1d6-436f-ba30-af8076970543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_defects_Sidewall</th>\n",
       "      <th>has_deffect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.310587e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.574766e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.083071e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.080907e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.791618e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.298618e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.591440e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.977833e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44159</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.581749e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44160</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.546029e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44161 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       perc_defects_Sidewall   has_deffect\n",
       "0                        0.0  2.310587e-01\n",
       "1                        0.0  6.574766e-02\n",
       "2                        0.0  1.083071e-01\n",
       "3                        0.0  3.080907e-03\n",
       "4                        0.0  7.791618e-07\n",
       "...                      ...           ...\n",
       "44156                    0.0  2.298618e-03\n",
       "44157                    0.0  1.591440e-03\n",
       "44158                    0.0  2.977833e-01\n",
       "44159                    0.0  1.581749e-02\n",
       "44160                    0.0  8.546029e-01\n",
       "\n",
       "[44161 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3c606-31b0-4e31-9b12-ec263cf760f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
